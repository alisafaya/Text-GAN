{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character language model for Turkish with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet, Test, Base.Iterators, Printf, LinearAlgebra, CuArrays, Random, IterTools, StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int2word (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Charset\n",
    "    c2i::Dict{Any,Int}\n",
    "    i2c::Vector{Any}\n",
    "    eow::Int\n",
    "end\n",
    "\n",
    "function Charset(charset::String; eow=\"\")\n",
    "    i2c = [ eow; [ c for c in charset ]  ]\n",
    "    print(i2c)\n",
    "    c2i = Dict( c => i for (i, c) in enumerate(i2c))\n",
    "    return Charset(c2i, i2c, c2i[eow])\n",
    "end\n",
    "\n",
    "struct TextReader\n",
    "    file::String\n",
    "    charset::Charset\n",
    "end\n",
    "\n",
    "function Base.iterate(r::TextReader, s=nothing)\n",
    "    s === nothing && (s = open(r.file))\n",
    "    eof(s) && return close(s)\n",
    "    return [ get(r.charset.c2i, c, r.charset.eow) for c in readline(s)], s\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{TextReader}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{TextReader}) = Base.HasEltype()\n",
    "Base.eltype(::Type{TextReader}) = Vector{Int}\n",
    "\n",
    "struct Embed; w; end\n",
    "\n",
    "function Embed(charsetsize::Int, embedsize::Int)\n",
    "    Embed(param(embedsize, charsetsize))\n",
    "end\n",
    "\n",
    "function (l::Embed)(x)\n",
    "    l.w[:, x]\n",
    "end\n",
    "\n",
    "struct Linear; w; end\n",
    "\n",
    "function Linear(inputsize::Int, outputsize::Int)\n",
    "    Linear(param(outputsize, inputsize))\n",
    "end\n",
    "\n",
    "function (l::Linear)(x)\n",
    "    l.w * x\n",
    "end\n",
    "\n",
    "function mask(a, pad)\n",
    "    a = copy(a)\n",
    "    for i in 1:size(a, 1)\n",
    "        j = size(a,2)\n",
    "        while a[i, j] == pad && j > 1\n",
    "            if a[i, j - 1] == pad\n",
    "                a[i, j] = 0\n",
    "            end\n",
    "            j -= 1\n",
    "        end\n",
    "    end\n",
    "    return a\n",
    "end\n",
    "\n",
    "struct WordsData\n",
    "    src::TextReader        \n",
    "    batchsize::Int         \n",
    "    maxlength::Int         \n",
    "    batchmajor::Bool       \n",
    "    bucketwidth::Int    \n",
    "    buckets::Vector        \n",
    "    batchmaker::Function   \n",
    "end\n",
    "\n",
    "function WordsData(src::TextReader; batchmaker = arraybatch, batchsize = 128, maxlength = typemax(Int),\n",
    "                batchmajor = false, bucketwidth = 2, numbuckets = min(128, maxlength ÷ bucketwidth))\n",
    "    buckets = [ [] for i in 1:numbuckets ] # buckets[i] is an array of sentence pairs with similar length\n",
    "    WordsData(src, batchsize, maxlength, batchmajor, bucketwidth, buckets, batchmaker)\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{WordsData}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{WordsData}) = Base.HasEltype()\n",
    "Base.eltype(::Type{WordsData}) = NTuple{2}\n",
    "\n",
    "function Base.iterate(d::WordsData, state=nothing)\n",
    "    if state == 0 # When file is finished but buckets are partially full \n",
    "        for i in 1:length(d.buckets)\n",
    "            if length(d.buckets[i]) > 0\n",
    "                batch = d.batchmaker(d, d.buckets[i])\n",
    "                d.buckets[i] = []\n",
    "                return batch, state\n",
    "            end\n",
    "        end\n",
    "        return nothing # Finish iteration\n",
    "    elseif state === nothing\n",
    "        # Just to make sure\n",
    "        for i in 1:length(d.buckets)\n",
    "            d.buckets[i] = []\n",
    "        end\n",
    "        state = nothing\n",
    "    end\n",
    "\n",
    "    while true\n",
    "        src_next = iterate(d.src, state)\n",
    "        \n",
    "        if src_next === nothing\n",
    "            state = 0\n",
    "            return iterate(d, state)\n",
    "        end\n",
    "        \n",
    "        (src_word, src_state) = src_next\n",
    "        state = src_state\n",
    "        src_length = length(src_word)\n",
    "        \n",
    "        (src_length > d.maxlength) && continue\n",
    "\n",
    "        i = Int(ceil(src_length / d.bucketwidth))\n",
    "        i > length(d.buckets) && (i = length(d.buckets))\n",
    "\n",
    "        push!(d.buckets[i], src_word)\n",
    "        if length(d.buckets[i]) == d.batchsize\n",
    "            batch = d.batchmaker(d, d.buckets[i])\n",
    "            d.buckets[i] = []\n",
    "            return batch, state\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function arraybatch(d::WordsData, bucket)\n",
    "    src_eow = d.src.charset.eow\n",
    "    src_lengths = map(x -> length(x), bucket)\n",
    "    max_length = max(src_lengths...)\n",
    "    x = zeros(Int64, length(bucket), max_length + 2) # default d.batchmajor is false\n",
    "\n",
    "    for (i, v) in enumerate(bucket)\n",
    "        to_be_added = fill(src_eow, max_length - length(v) + 1)\n",
    "        x[i,:] = [src_eow; v; to_be_added]\n",
    "    end\n",
    "\n",
    "    \n",
    "    d.batchmajor && (x = x')\n",
    "    return (x[:, 1:end-1], x[:, 2:end])\n",
    "end\n",
    "\n",
    "# per-word loss (in this case per-batch loss)\n",
    "function loss(model, data; average=true)\n",
    "    l = 0\n",
    "    n = 0\n",
    "    a = 0\n",
    "    for (x, y) in data\n",
    "        v = model(x, y; average=false)\n",
    "        l += v[1]\n",
    "        n += v[2]\n",
    "        a += (v[1] / v[2])\n",
    "    end\n",
    "    average && return a\n",
    "    return l, n\n",
    "end\n",
    "\n",
    "# Utility to convert int arrays to sentence strings\n",
    "function int2word(y, charset)\n",
    "    y = vec(y)\n",
    "    ysos = findnext(w->!isequal(w, charset.eow), y, 1)\n",
    "    ysos == nothing && return \"\"\n",
    "    yeos = something(findnext(isequal(charset.eow), y, ysos), 1+length(y))\n",
    "    join(charset.i2c[y[ysos:yeos-1]], \" \")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'y', 'z', 'Ç', 'Ö', 'Ü', 'ç', 'ö', 'ü', 'Ğ', 'ğ', 'İ', 'ı', 'Ş', 'ş']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Reading data\n",
      "└ @ Main In[8]:5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WordsData(TextReader(\"turkish_word_set/dev.tr\", Charset(Dict{Any,Int64}('ç' => 51,'Ğ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ğ' => 55…), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  …  'Ü', 'ç', 'ö', 'ü', 'Ğ', 'ğ', 'İ', 'ı', 'Ş', 'ş'], 1)), 32, 25, false, 3, Array{Any,1}[[], [], [], [], [], [], [], []], arraybatch)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_set = \"ABCDEFGHIJKLMNOPRSTUVYZabcdefghijklmnoprstuvyzÇÖÜçöüĞğİıŞş\"\n",
    "datadir = \"turkish_word_set\"\n",
    "\n",
    "BATCHSIZE, MAXLENGTH = 32, 25\n",
    "@info \"Reading data\"\n",
    "tr_charset = Charset(char_set)\n",
    "tr_train = TextReader(\"$datadir/train.tr\", tr_charset)\n",
    "tr_dev = TextReader(\"$datadir/dev.tr\", tr_charset)\n",
    "dtrn = WordsData(tr_train, batchsize=BATCHSIZE, maxlength=MAXLENGTH, bucketwidth = 3)\n",
    "ddev = WordsData(tr_dev, batchsize=BATCHSIZE, maxlength=MAXLENGTH, bucketwidth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74076-element Array{Any,1}:\n",
       " \"detayları\"    \n",
       " \"GİRİYOR\"      \n",
       " \"Tamamiyle\"    \n",
       " \"haberleşmeye\" \n",
       " \"yazılarımız\"  \n",
       " \"veresiye\"     \n",
       " \"kumaşlar\"     \n",
       " \"Kolektif\"     \n",
       " \"EPO\"          \n",
       " \"ettirerek\"    \n",
       " \"açıklanmaması\"\n",
       " \"başlıcak\"     \n",
       " \"Huysuz\"       \n",
       " ⋮              \n",
       " \"tahdidi\"      \n",
       " \"Sharm\"        \n",
       " \"yavaşlatacak\" \n",
       " \"Belçikalılar\" \n",
       " \"Kebabı\"       \n",
       " \"EDERİM\"       \n",
       " \"geçenleri\"    \n",
       " \"Raporlar\"     \n",
       " \"yat\"          \n",
       " \"Dağlaroğlu\"   \n",
       " \"girişiminiz\"  \n",
       " \"vereni\"       "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function readwordset(fname)\n",
    "    words = []\n",
    "    fi = open(fname)\n",
    "    while !eof(fi)\n",
    "        push!(words, readline(fi))\n",
    "    end\n",
    "    close(fi)\n",
    "    words\n",
    "end\n",
    "\n",
    "training_set = readwordset(\"$datadir/train.tr\")\n",
    "test_set = [ readwordset(\"$datadir/test.tr\"); readwordset(\"$datadir/dev.tr\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LModel"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct LModel\n",
    "    srcembed::Embed\n",
    "    rnn::RNN        \n",
    "    projection::Linear  \n",
    "    dropout::Real\n",
    "    srccharset::Charset \n",
    "end\n",
    "\n",
    "function LModel(hidden::Int, srcembsz::Int, srccharset::Charset;\n",
    "             layers=1, dropout=0)\n",
    "    \n",
    "    srcembed = Embed(length(srccharset.i2c), srcembsz)\n",
    "    rnn = RNN(srcembsz, hidden; bidirectional=false, numLayers=layers, dropout=dropout)\n",
    "    projection = Linear(hidden, length(srccharset.i2c))\n",
    "    \n",
    "    LModel(srcembed, rnn, projection, dropout, srccharset)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (s::LModel)(src, tgt; average=true)\n",
    "    s.rnn.h, s.rnn.c = 0, 0\n",
    "    srcembed = s.srcembed(src)\n",
    "    rnn_out = s.rnn(srcembed)\n",
    "    dims = size(rnn_out)\n",
    "    output = s.projection(dropout(reshape(rnn_out, dims[1], dims[2] * dims[3]), s.dropout))\n",
    "    scores = reshape(output, size(output, 1), dims[2], dims[3])\n",
    "    nll(scores, mask(tgt, s.srccharset.eow); dims=1, average=average)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing LModel\n",
      "└ @ Main In[12]:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model(x, y; average=false) = (1582.5035f0, 388)\n"
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: dtst not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: dtst not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at show.jl:576",
      " [2] top-level scope at In[12]:6"
     ]
    }
   ],
   "source": [
    "@info \"Testing LModel\"\n",
    "Knet.seed!(1)\n",
    "model = LModel(128, 128, tr_charset; layers=2, dropout=0.2)\n",
    "(x, y) = first(dtrn)\n",
    "@show model(x, y; average=false)\n",
    "@show loss(model, ddev, average=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train! (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train!(model, trn, dev, tst...)\n",
    "    bestmodel, bestloss = deepcopy(model), loss(model, dev)\n",
    "    progress!(adam(model, trn), seconds=30) do y\n",
    "        devloss = loss(model, dev)\n",
    "        tstloss = map(d->loss(model,d), tst)\n",
    "        if devloss < bestloss\n",
    "            bestloss, bestmodel = devloss, deepcopy(model)\n",
    "        end\n",
    "        println(stderr)\n",
    "        (dev=devloss, tst=tstloss, mem=Float32(CuArrays.usage[]))\n",
    "    end\n",
    "    return bestmodel\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training S2S_v1\n",
      "└ @ Main In[75]:1\n",
      "\n",
      "┣                    ┫ [0.03%, 1/3028, 00:02/01:35:49, 1.90s/i] (dev = 12749.384f0, tst = (81.51515f0,), mem = 6.7731315f8)\n",
      "┣███████████████████▉┫ [100.00%, 3028/3028, 00:11/00:11, 278.75i/s] (dev = 8216.36f0, tst = (51.469f0,), mem = 7.5804736f8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LModel(Embed(P(KnetArray{Float32,2}(16,59))), LSTM(input=16,hidden=16,layers=2,dropout=0.2), Linear(P(KnetArray{Float32,2}(59,16))), 0.2, Charset(Dict{Any,Int64}('ç' => 51,'Ğ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ğ' => 55…), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  …  'Ü', 'ç', 'ö', 'ü', 'Ğ', 'ğ', 'İ', 'ı', 'Ş', 'ş'], 1))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Training S2S_v1\"\n",
    "epochs = 4\n",
    "ctrn = collect(ddev)\n",
    "trnx10 = collect(flatten(shuffle!(ctrn) for i in 1:epochs))\n",
    "trnmini = ctrn[1:20]\n",
    "dev = collect(dtrn)\n",
    "\n",
    "model = LModel(16, 16, tr_charset; layers=2, dropout=0.2)\n",
    "model = train!(model, trnx10, dev, trnmini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate (generic function with 1 method)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function generate(s::LModel; start=\"\", maxlength=30)\n",
    "    s.rnn.h, s.rnn.c = 0, 0\n",
    "    chars = fill(s.srccharset.eow, 1)\n",
    "    \n",
    "    starting_index = 1\n",
    "    for i in 1:length(start)\n",
    "        push!(chars, s.srccharset.c2i[start[i]])\n",
    "        charembed = s.srcembed(chars[i:i])\n",
    "        rnn_out = s.rnn(charembed)\n",
    "        starting_index += 1\n",
    "    end\n",
    "    \n",
    "    for i in starting_index:maxlength\n",
    "        charembed = s.srcembed(chars[i:i])\n",
    "        rnn_out = s.rnn(charembed)\n",
    "        output = model.projection(dropout(rnn_out, model.dropout))\n",
    "        push!(chars, s.srccharset.c2i[ sample(s.srccharset.i2c, Weights(Array(softmax(reshape(output, length(s.srccharset.i2c)))))) ] )\n",
    "        \n",
    "        if chars[end] == s.srccharset.eow\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    join([ s.srccharset.i2c[i] for i in chars ], \"\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_words = [ generate(model) for c in 1:100 ]\n",
    "intest = [ w for w in generated_words if w in test_set]         \n",
    "notintraining = [ w for w in generated_words if !(w in training_set)]\n",
    "\n",
    "println(100 - length(notintraining) , \"% of the generated words are words in training set\")  \n",
    "println(length(intest), \"% of the generated words are real words that are in the test set\")\n",
    "println(\"\\nExamples of the new generated words:\")\n",
    "println(join(notintraining, \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Array{String,1}:\n",
       " \"lutu\"        \n",
       " \"less\"        \n",
       " \"lıegenler\"   \n",
       " \"lafın\"       \n",
       " \"lütresi\"     \n",
       " \"leylerin\"    \n",
       " \"laflarında\"  \n",
       " \"lokuma\"      \n",
       " \"limin\"       \n",
       " \"lishenlerini\"\n",
       " \"limyol\"      \n",
       " \"leck\"        \n",
       " \"larımın\"     \n",
       " ⋮             \n",
       " \"latını\"      \n",
       " \"lepsizlikte\" \n",
       " \"larik\"       \n",
       " \"labikatınız\" \n",
       " \"leke\"        \n",
       " \"lefiği\"      \n",
       " \"log\"         \n",
       " \"laftan\"      \n",
       " \"lameresinde\" \n",
       " \"lasmanı\"     \n",
       " \"lakiyelerde\" \n",
       " \"likandınin\"  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_words = [ generate(model; start=\"l\") for c in 1:100 ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
