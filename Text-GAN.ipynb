{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-GAN Turkish word generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readwordset (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Knet, Test, Base.Iterators, Printf, LinearAlgebra, CuArrays, Random, IterTools, StatsBase\n",
    "\n",
    "struct Charset\n",
    "    c2i::Dict{Any,Int}\n",
    "    i2c::Vector{Any}\n",
    "    eow::Int\n",
    "end\n",
    "\n",
    "function Charset(charset::String; eow=\"\")\n",
    "    i2c = [ eow; [ c for c in charset ]  ]\n",
    "    print(i2c)\n",
    "    c2i = Dict( c => i for (i, c) in enumerate(i2c))\n",
    "    return Charset(c2i, i2c, c2i[eow])\n",
    "end\n",
    "\n",
    "struct TextReader\n",
    "    file::String\n",
    "    charset::Charset\n",
    "end\n",
    "\n",
    "function Base.iterate(r::TextReader, s=nothing)\n",
    "    s === nothing && (s = open(r.file))\n",
    "    eof(s) && return close(s)\n",
    "    return [ get(r.charset.c2i, c, r.charset.eow) for c in readline(s)], s\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{TextReader}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{TextReader}) = Base.HasEltype()\n",
    "Base.eltype(::Type{TextReader}) = Vector{Int}\n",
    "\n",
    "struct WordsData\n",
    "    src::TextReader        \n",
    "    batchsize::Int         \n",
    "    maxlength::Int         \n",
    "    batchmajor::Bool       \n",
    "    bucketwidth::Int    \n",
    "    buckets::Vector        \n",
    "end\n",
    "\n",
    "function WordsData(src::TextReader; batchsize = 128, maxlength = typemax(Int),\n",
    "                batchmajor = false, bucketwidth = 2, numbuckets = min(128, maxlength รท bucketwidth))\n",
    "    buckets = [ [] for i in 1:numbuckets ] # buckets[i] is an array of sentence pairs with similar length\n",
    "    WordsData(src, batchsize, maxlength, batchmajor, bucketwidth, buckets)\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{WordsData}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{WordsData}) = Base.HasEltype()\n",
    "Base.eltype(::Type{WordsData}) = NTuple{2}\n",
    "\n",
    "function Base.iterate(d::WordsData, state=nothing)\n",
    "    if state == 0 # When file is finished but buckets are partially full \n",
    "        for i in 1:length(d.buckets)\n",
    "            if length(d.buckets[i]) > 0\n",
    "                buc = d.buckets[i]\n",
    "                d.buckets[i] = []\n",
    "                return buc, state\n",
    "            end\n",
    "        end\n",
    "        return nothing # Finish iteration\n",
    "    end\n",
    "\n",
    "    while true\n",
    "        src_next = iterate(d.src, state)\n",
    "        \n",
    "        if src_next === nothing\n",
    "            state = 0\n",
    "            return iterate(d, state)\n",
    "        end\n",
    "        \n",
    "        (src_word, src_state) = src_next\n",
    "        state = src_state\n",
    "        src_length = length(src_word)\n",
    "        \n",
    "        (src_length > d.maxlength) && continue\n",
    "\n",
    "        i = Int(ceil(src_length / d.bucketwidth))\n",
    "        i > length(d.buckets) && (i = length(d.buckets))\n",
    "\n",
    "        push!(d.buckets[i], src_word)\n",
    "        if length(d.buckets[i]) == d.batchsize\n",
    "            buc = d.buckets[i]\n",
    "            d.buckets[i] = []\n",
    "            return buc, state\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function readwordset(fname)\n",
    "    words = []\n",
    "    fi = open(fname)\n",
    "    while !eof(fi)\n",
    "        push!(words, readline(fi))\n",
    "    end\n",
    "    close(fi)\n",
    "    words\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G/D Common Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Embed; w; end\n",
    "\n",
    "function Embed(shape...)\n",
    "    Embed(param(shape...))\n",
    "end\n",
    "\n",
    "# per-word loss (in this case per-batch loss)\n",
    "function loss(model, data; average=true)\n",
    "    l = 0\n",
    "    n = 0\n",
    "    a = 0\n",
    "    for (x, y) in data\n",
    "        v = model(x, y; average=false)\n",
    "        l += v[1]\n",
    "        n += v[2]\n",
    "        a += (v[1] / v[2])\n",
    "    end\n",
    "    average && return a\n",
    "    return l, n\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one to be used by DModel, takes weights of characters and reduce the embedding for each character\n",
    "# this approach to avoid sampling or argmaxing over rnn's output\n",
    "# (C, B, T) -> (T, E, 1, B)\n",
    "\n",
    "# function (l::Embed)(x)\n",
    "#     dims = size(x)\n",
    "#     em = l.w * reshape(x, dims[1], dims[2] * dims[3]) # reshape for multiplication \n",
    "#     em = reshape(em, size(em, 1), dims[2], dims[3]) # reshape to original size\n",
    "#     em = permutedims(em, [3, 1, 2])  # permute for CONV\n",
    "#     em = reshape(em, dims[3], size(em, 2), 1, dims[2]) # Add one dim for CONV\n",
    "# end\n",
    "\n",
    "# struct Conv; w; b; f; p; end\n",
    "# (c::Conv)(x) = (co=conv4(c.w, dropout(x,c.p)); c.f.(pool((co .+ c.b); window=(size(co, 1), size(co, 2)))))\n",
    "# Conv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)\n",
    "\n",
    "# struct Dense; w; b; f; p; end\n",
    "# (d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul\n",
    "# Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i), param0(o), f, pdrop)\n",
    "\n",
    "# # Perform convolution then, global-max pooling and concatenate the output and feed it to sequential dense layer \n",
    "# mutable struct DisModel\n",
    "#     charset::Charset\n",
    "#     embed::Embed\n",
    "#     filters\n",
    "#     dense_layers\n",
    "# end\n",
    "\n",
    "# # This discriminator uses separate weights for its embedding layer\n",
    "# function DisModel(charset, embeddingSize::Int, filters, denselayers)\n",
    "#     Em = Embed(embeddingSize, length(tr_charset.c2i))\n",
    "#     DisModel(charset, Em, filters, denselayers)\n",
    "# end\n",
    "\n",
    "# function (c::DisModel)(x) # the input here is weights of the characters with shape (C, B, T)\n",
    "#     em = c.embed(x)\n",
    "#     filters_out = []\n",
    "#     for f in c.filters\n",
    "#         push!(filters_out, f(em))\n",
    "#     end\n",
    "#     max_out = cat(filters_out...;dims=3)\n",
    "#     for l in c.dense_layers\n",
    "#         max_out = l(max_out)\n",
    "#     end\n",
    "#     max_out\n",
    "# end\n",
    "\n",
    "# (c::DisModel)(x,y; average=true) = nll(c(x), y; average=average)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (l::Embed)(x)\n",
    "    dims = size(x)\n",
    "    em = l.w * reshape(x, dims[1], dims[2] * dims[3]) # reshape for multiplication \n",
    "    em = reshape(em, size(em, 1), dims[2], dims[3]) # reshape to original size\n",
    "end\n",
    "\n",
    "struct Dense; w; b; f; p; end\n",
    "(d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 3-D tensor to 2-D matrix so we can use matmul\n",
    "Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i), param0(o), f, pdrop)\n",
    "\n",
    "mutable struct DisModel\n",
    "    charset::Charset\n",
    "    embed::Embed\n",
    "    rnn::RNN\n",
    "    denselayers\n",
    "end\n",
    "\n",
    "# This discriminator uses separate weights for its embedding layer\n",
    "function DisModel(charset, embeddingSize::Int, hidden, denselayers; layers=1, dropout=0)\n",
    "    Em = Embed(embeddingSize, length(tr_charset.c2i))\n",
    "    rnn = RNN(embeddingSize, hidden; numLayers=layers, dropout=dropout)\n",
    "    DisModel(charset, Em, rnn, denselayers)\n",
    "end\n",
    "\n",
    "function (c::DisModel)(x) # the input here is weights of the characters with shape (C, B, T)\n",
    "    c.rnn.h, c.rnn.c = 0, 0\n",
    "    em = c.embed(x)\n",
    "    rnn_out = permutedims(c.rnn(em), [1, 3, 2])\n",
    "    for l in c.denselayers\n",
    "        rnn_out = l(rnn_out)\n",
    "    end\n",
    "    rnn_out\n",
    "end\n",
    "\n",
    "(c::DisModel)(x,y; average=true) = nll(c(x), y; average=average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_z(shape...) = KnetArray(randn(Float32, shape...))\n",
    "\n",
    "### Not used \n",
    "# concatenate z with embedding vectors, z -> (z_size, B), returns (E+z_size, B, T)\n",
    "# this will be used to feed Z to generator at each timestep\n",
    "# function (l::Embed)(x, z)\n",
    "#     em = l.w[:, x]\n",
    "#     z_array = cat((z for i in 1:size(em, 3))...; dims=(3))\n",
    "#     cat(em, z_array; dims=(1))\n",
    "# end\n",
    "\n",
    "# Generator model\n",
    "struct GenModel\n",
    "    projection::Embed\n",
    "    rnn::RNN        \n",
    "    dropout::Real\n",
    "    charset::Charset\n",
    "    disModel::DisModel\n",
    "    maxlength::Int\n",
    "end\n",
    "\n",
    "function GenModel(inputsize::Int, hidden::Int, charset::Charset, disModel::DisModel, maxlength::Int; layers=2, dropout=0)\n",
    "    rnn = RNN(inputsize, hidden; numLayers=layers, dropout=dropout)\n",
    "    projection = Embed(hidden, length(charset.i2c))\n",
    "    GenModel(projection, rnn, dropout, charset, disModel, maxlength)\n",
    "end\n",
    "\n",
    "# This generator shares the projection layers weights of the discriminator for its projection layer\n",
    "function GenModel(inputsize::Int, charset::Charset, disModel::DisModel, maxlength::Int; layers=2, dropout=0)\n",
    "    rnn = RNN(inputsize, size(disModel.embed.w, 1); numLayers=layers, dropout=dropout)\n",
    "    GenModel(disModel.embed, rnn, dropout, charset, disModel, maxlength)\n",
    "end\n",
    "\n",
    "function Z(s::GenModel, batchsize, timesteps)\n",
    "    z = get_z(s.rnn.inputSize, batchsize, 1) # according to get_z(H, B, layers)\n",
    "    return cat([ z for i in 1:timesteps]...;dims=3)\n",
    "end\n",
    "\n",
    "# Generator forward pass, size(Z) -> inputsize, batchsize, sequencelength\n",
    "function (s::GenModel)(Z)\n",
    "    s.rnn.h, s.rnn.c = 0, 0\n",
    "    rnn_out = s.rnn(Z) \n",
    "    dims = size(rnn_out)\n",
    "    output = s.projection.w' * dropout(reshape(rnn_out, dims[1], dims[2] * dims[3]), s.dropout)\n",
    "    reshape(softmax(output), size(output, 1), dims[2], dims[3])\n",
    "end\n",
    "\n",
    "# Generator loss\n",
    "function (s::GenModel)(Z, calculateloss::Int; average=true)\n",
    "    y = Array(ones(Int, size(Z, 2))) # create labels 1 -> real, 2-> not-real\n",
    "    x = s(Z)\n",
    "    pads = KnetArray(zeros(Float32, size(x, 1), size(x, 2), s.maxlength - size(x, 3)))\n",
    "    pads[s.charset.eow, :, :] .= 1\n",
    "    x = cat(x, pads; dims=3) # padding\n",
    "    return s.disModel(x, y;average=average) \n",
    "end\n",
    "\n",
    "function generate(s::GenModel, maxlength, batchsize)\n",
    "    out = s(Z(s, batchsize, maxlength))\n",
    "    words = []\n",
    "    for i in 1:batchsize\n",
    "        push!(words, join([s.charset.i2c[x[1]] for x in argmax(out[:, i, :]; dims=1)], \"\"))\n",
    "    end\n",
    "    words\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word sampler will be used to train discriminator.\n",
    "this sampler should take B, T (batchsize, timestep) as parameters\n",
    "returns (X, Y) tuple \n",
    "where X is tensor of size (C, B, T)\n",
    "and Y is array of size B\n",
    "B consists of real words and generated words\n",
    "C charset size where each value is weight of this char\n",
    "in the case of generated words the generator already gives C, B, T\n",
    "for real words we need to convert words to C, T arrays\n",
    "where every character can be represented by one hot vector or by Gumble-Max (which is normalized one hot vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Sampler\n",
    "    wordsdata::WordsData\n",
    "    charset::Charset\n",
    "    genModel::GenModel\n",
    "    maxBatchsize::Int\n",
    "end\n",
    "\n",
    "# this function is similar to gumble softmax, it is used to soften the one-hot-vector of the real samples\n",
    "# tau -> normalization factor; the bigger the softer\n",
    "function soften(A; dims=1, tau=2.0) \n",
    "    A = A ./ tau\n",
    "    softmax(A; dims=dims)\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{Sampler}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{Sampler}) = Base.HasEltype()\n",
    "Base.eltype(::Type{Sampler}) = Tuple{KnetArray{Float32,3},Array{Int64,1}}\n",
    "\n",
    "function Base.iterate(s::Sampler, state=nothing)\n",
    "    wdatastate = iterate(s.wordsdata, state)\n",
    "    wdatastate === nothing && (return nothing)\n",
    "    \n",
    "    (bucket, state) = wdatastate\n",
    "    bsize = length(bucket)\n",
    "    src_eow = s.charset.eow\n",
    "    src_lengths = map(x -> length(x), bucket)\n",
    "    max_length = max(src_lengths...)\n",
    "    gsize = 1 + rand(bsize:s.maxBatchsize) - bsize # count of words to be generated\n",
    "    generated = s.genModel(Z(s.genModel, gsize, max_length))\n",
    "\n",
    "    to_be_cat = [generated, ]\n",
    "    for (i, v) in enumerate(bucket)\n",
    "        tindex = [i for i in 1:length(v)]\n",
    "        onehot = KnetArray(zeros(Float32, length(s.charset.c2i), 1, max_length))\n",
    "        onehot[v, :, tindex] .= 1\n",
    "        onehot = soften(onehot) # soften one hot vectors elements value\n",
    "        push!(to_be_cat, onehot)\n",
    "    end\n",
    "    x = cat(to_be_cat...;dims=2) # concatenate both generated and sampled words\n",
    "    pads = KnetArray(zeros(Float32, size(x, 1), size(x, 2), s.wordsdata.maxlength - size(x, 3)))\n",
    "    pads[s.charset.eow, :, :] .= 1\n",
    "    \n",
    "#     pads = soften(pads) # getting error \n",
    "\n",
    "    x = cat(x, pads; dims=3) # padding\n",
    "    y = Array(ones(Int, gsize+bsize)) # create labels 1 -> real, 2-> not-real\n",
    "    y[1:gsize] = y[1:gsize] .+ 1\n",
    "    \n",
    "    ind = shuffle(1:gsize+bsize) # used to shuffle the batch\n",
    "    x, y = x[:, ind, :], y[ind]\n",
    "    return (x,y), state\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train! (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train!(model, parameters, trn, dev, tst...)\n",
    "    bestmodel, bestloss = deepcopy(model), loss(model, dev)\n",
    "    progress!(adam(model, trn; params=parameters), seconds=30) do y\n",
    "        devloss = loss(model, dev)\n",
    "        tstloss = map(d->loss(model,d), tst)\n",
    "        if devloss < bestloss\n",
    "            bestloss, bestmodel = devloss, deepcopy(model)\n",
    "        end\n",
    "        println(stderr)\n",
    "        (dev=devloss, tst=tstloss, mem=Float32(CuArrays.usage[]))\n",
    "    end\n",
    "    return bestmodel\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-word loss (in this case per-batch loss)\n",
    "function loss(model, data; average=true)\n",
    "    l = 0\n",
    "    n = 0\n",
    "    a = 0\n",
    "    for (x, y) in data\n",
    "        v = model(x, y; average=false)\n",
    "        l += v[1]\n",
    "        n += v[2]\n",
    "        a += (v[1] / v[2])\n",
    "    end\n",
    "    average && return a\n",
    "    return l, n\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'y', 'z', 'ร', 'ร', 'ร', 'รง', 'รถ', 'รผ', 'ฤ', 'ฤ', 'ฤฐ', 'ฤฑ', 'ล', 'ล']"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WordsData(TextReader(\"turkish_word_set/dev.tr\", Charset(Dict{Any,Int64}('รง' => 51,'ฤ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ฤ' => 55โฆ), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  โฆ  'ร', 'รง', 'รถ', 'รผ', 'ฤ', 'ฤ', 'ฤฐ', 'ฤฑ', 'ล', 'ล'], 1)), 128, 7, false, 1, Array{Any,1}[[], [], [], [], [], [], []])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_set = \"ABCDEFGHIJKLMNOPRSTUVYZabcdefghijklmnoprstuvyzรรรรงรถรผฤฤฤฐฤฑลล\"\n",
    "tr_charset = Charset(char_set)\n",
    "datadir = \"turkish_word_set\"\n",
    "BATCHSIZE = 128\n",
    "MAXLENGTH = 7\n",
    "tr_dev = TextReader(\"$datadir/dev.tr\", tr_charset)\n",
    "tr_trn = TextReader(\"$datadir/train.tr\", tr_charset)\n",
    "dtrn = WordsData(tr_trn, batchsize=BATCHSIZE, maxlength=MAXLENGTH, bucketwidth = 1)\n",
    "ddev = WordsData(tr_dev, batchsize=BATCHSIZE, maxlength=MAXLENGTH, bucketwidth = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sampler(WordsData(TextReader(\"turkish_word_set/dev.tr\", Charset(Dict{Any,Int64}('รง' => 51,'ฤ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ฤ' => 55โฆ), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  โฆ  'ร', 'รง', 'รถ', 'รผ', 'ฤ', 'ฤ', 'ฤฐ', 'ฤฑ', 'ล', 'ล'], 1)), 128, 7, false, 1, Array{Any,1}[[], [], [], [], [], [], []]), Charset(Dict{Any,Int64}('รง' => 51,'ฤ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ฤ' => 55โฆ), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  โฆ  'ร', 'รง', 'รถ', 'รผ', 'ฤ', 'ฤ', 'ฤฐ', 'ฤฑ', 'ล', 'ล'], 1), GenModel(Embed(P(KnetArray{Float32,2}(256,59))), LSTM(input=128,hidden=256,layers=2,dropout=0.2), 0.2, Charset(Dict{Any,Int64}('รง' => 51,'ฤ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ฤ' => 55โฆ), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  โฆ  'ร', 'รง', 'รถ', 'รผ', 'ฤ', 'ฤ', 'ฤฐ', 'ฤฑ', 'ล', 'ล'], 1), DisModel(Charset(Dict{Any,Int64}('รง' => 51,'ฤ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ฤ' => 55โฆ), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  โฆ  'ร', 'รง', 'รถ', 'รผ', 'ฤ', 'ฤ', 'ฤฐ', 'ฤฑ', 'ล', 'ล'], 1), Embed(P(KnetArray{Float32,2}(64,59))), LSTM(input=64,hidden=128,dropout=0.2), (Dense(P(KnetArray{Float32,2}(16,896)), P(KnetArray{Float32,1}(16)), NNlib.relu, 0.2), Dense(P(KnetArray{Float32,2}(2,16)), P(KnetArray{Float32,1}(2)), Knet.sigm, 0.2))), 7), 256)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 64\n",
    "DHIDDEN_SIZE = 128\n",
    "GDROPOUT = 0.2\n",
    "DDROPOUT = 0.2\n",
    "\n",
    "dismodel = DisModel(tr_charset, EMBEDDING_SIZE, DHIDDEN_SIZE,(\n",
    "        Dense(DHIDDEN_SIZE * MAXLENGTH, 16, pdrop=DDROPOUT),\n",
    "        Dense(16, 2, sigm, pdrop=0.2)\n",
    "        ); dropout=DDROPOUT)\n",
    "\n",
    "GE_SIZE = 256\n",
    "Z_SIZE = 128\n",
    "\n",
    "genmodel = GenModel(Z_SIZE, GE_SIZE, tr_charset, dismodel, MAXLENGTH; dropout=GDROPOUT, layers=2)\n",
    "trnsampler = Sampler(dtrn, tr_charset, genmodel, BATCHSIZE * 2)\n",
    "devsampler = Sampler(ddev, tr_charset, genmodel, BATCHSIZE * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "โ Info: Started training...\n",
      "โ @ Main In[29]:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn no:1\n",
      "Ex.Generated words: VVVVVVV\n",
      "รรรkkkk\n",
      "ttรงรงรงรงรง\n",
      "ฤฐฤฐbbbbb\n",
      "vvvvvฤฐฤฐ\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโโ                  โซ [10.00%, 1/10, 00:00/00:01, 10.64i/s] (dev = 50.550514f0, tst = (13.850113f0,), mem = 2.8813647f9)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 10/10, 00:00/00:00, 65.72i/s] (dev = 49.052547f0, tst = (13.487146f0,), mem = 2.8834696f9)\n",
      "\n",
      "โฃ                    โซ [0.10%, 1/1000, 00:00/03:56, 4.24i/s] (dev = 66.78007f0, tst = (13.356004f0,), mem = 7.971089f9)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 1000/1000, 00:05/00:05, 194.71i/s] (dev = 66.772545f0, tst = (13.354519f0,), mem = 1.3836291f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:2\n",
      "Ex.Generated words: sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโโ                  โซ [9.09%, 1/11, 00:00/00:01, 19.76i/s] (dev = 48.73716f0, tst = (13.2623825f0,), mem = 1.3836448f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 11/11, 00:00/00:00, 100.53i/s] (dev = 42.06518f0, tst = (11.030857f0,), mem = 1.3836448f10)\n",
      "\n",
      "โฃ                    โซ [0.03%, 1/3000, 00:00/06:59, 7.15i/s] (dev = 66.772545f0, tst = (13.354521f0,), mem = 1.3836448f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 3000/3000, 00:13/00:13, 230.44i/s] (dev = 66.772545f0, tst = (13.35452f0,), mem = 1.3937111f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:3\n",
      "Ex.Generated words: ssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "ssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโโ                  โซ [10.00%, 1/10, 00:00/00:01, 19.82i/s] (dev = 40.685947f0, tst = (10.366326f0,), mem = 1.3937127f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 10/10, 00:00/00:00, 93.19i/s] (dev = 36.221367f0, tst = (9.186247f0,), mem = 1.3937127f10)\n",
      "\n",
      "โฃ                    โซ [0.05%, 1/2000, 00:00/04:30, 7.40i/s] (dev = 66.77254f0, tst = (13.354519f0,), mem = 1.3937127f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 2000/2000, 00:09/00:09, 230.89i/s] (dev = 66.77254f0, tst = (13.354516f0,), mem = 1.3812986f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:4\n",
      "Ex.Generated words: sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโโโ                 โซ [14.29%, 1/7, 00:00/00:01, 13.22i/s] (dev = 34.70887f0, tst = (9.379989f0,), mem = 1.1734063f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 7/7, 00:00/00:00, 55.55i/s] (dev = 31.616816f0, tst = (8.5753355f0,), mem = 1.1734063f10)\n",
      "\n",
      "โฃ                    โซ [0.02%, 1/4500, 00:00/10:08, 7.41i/s] (dev = 66.77254f0, tst = (13.354519f0,), mem = 1.2110756f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 4500/4500, 00:19/00:19, 234.54i/s] (dev = 66.77254f0, tst = (13.354523f0,), mem = 1.186733f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:5\n",
      "Ex.Generated words: sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโโโ                 โซ [11.11%, 1/9, 00:00/00:01, 15.76i/s] (dev = 33.15883f0, tst = (8.8484955f0,), mem = 1.1950488f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 9/9, 00:00/00:00, 76.54i/s] (dev = 31.002481f0, tst = (8.33415f0,), mem = 1.1950488f10)\n",
      "\n",
      "โฃ                    โซ [0.03%, 1/3500, 00:00/08:49, 6.62i/s] (dev = 66.77254f0, tst = (13.354519f0,), mem = 1.249365f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 3500/3500, 00:16/00:16, 223.44i/s] (dev = 66.77254f0, tst = (13.354515f0,), mem = 1.2678703f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:6\n",
      "Ex.Generated words: sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโ                   โซ [4.55%, 1/22, 00:00/00:01, 19.10i/s] (dev = 30.788013f0, tst = (8.158402f0,), mem = 1.2678742f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 22/22, 00:00/00:00, 162.11i/s] (dev = 23.03034f0, tst = (6.305452f0,), mem = 1.2678745f10)\n",
      "\n",
      "โฃ                    โซ [0.03%, 1/3000, 00:00/06:41, 7.48i/s] (dev = 66.77254f0, tst = (13.35452f0,), mem = 1.2678745f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 3000/3000, 00:13/00:13, 233.50i/s] (dev = 66.77254f0, tst = (13.354517f0,), mem = 1.2712197f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:7\n",
      "Ex.Generated words: sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโ                   โซ [5.00%, 1/20, 00:00/00:01, 20.65i/s] (dev = 22.986294f0, tst = (6.2994094f0,), mem = 1.2712283f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 20/20, 00:00/00:00, 158.17i/s] (dev = 22.87265f0, tst = (6.266535f0,), mem = 1.2712287f10)\n",
      "\n",
      "โฃ                    โซ [0.04%, 1/2500, 00:00/05:36, 7.44i/s] (dev = 66.77254f0, tst = (13.354517f0,), mem = 1.2712287f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 2500/2500, 00:11/00:11, 229.38i/s] (dev = 66.77254f0, tst = (13.354517f0,), mem = 1.3570786f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:8\n",
      "Ex.Generated words: sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโโโ                 โซ [12.50%, 1/8, 00:00/00:01, 14.38i/s] (dev = 22.87233f0, tst = (6.2662687f0,), mem = 1.3093236f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 8/8, 00:00/00:00, 65.77i/s] (dev = 22.870625f0, tst = (6.2658606f0,), mem = 1.3093236f10)\n",
      "\n",
      "โฃ                    โซ [0.10%, 1/1000, 00:00/02:19, 7.22i/s] (dev = 66.77254f0, tst = (13.354521f0,), mem = 1.3093236f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 1000/1000, 00:04/00:04, 223.59i/s] (dev = 66.772545f0, tst = (13.35452f0,), mem = 1.2718644f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:9\n",
      "Ex.Generated words: sssss\n",
      "ssss\n",
      "sssss\n",
      "ssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโโโ                 โซ [12.50%, 1/8, 00:00/00:00, 17.38i/s] (dev = 22.870375f0, tst = (6.265909f0,), mem = 1.2485471f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 8/8, 00:00/00:00, 69.94i/s] (dev = 22.869791f0, tst = (6.265723f0,), mem = 1.2485471f10)\n",
      "\n",
      "โฃ                    โซ [0.02%, 1/4500, 00:00/10:19, 7.27i/s] (dev = 66.77254f0, tst = (13.354523f0,), mem = 1.297437f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 4500/4500, 00:20/00:20, 227.17i/s] (dev = 66.77254f0, tst = (13.354514f0,), mem = 1.3106704f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:10\n",
      "Ex.Generated words: ssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 1/1, 00:00/00:00, 16.86i/s] (dev = 22.869762f0, tst = (6.265684f0,), mem = 1.2219184f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 1/1, 00:00/00:00, 10.50i/s] (dev = 22.869762f0, tst = (6.265684f0,), mem = 1.2219184f10)\n",
      "\n",
      "โฃ                    โซ [0.03%, 1/3500, 00:00/08:05, 7.22i/s] (dev = 66.77254f0, tst = (13.354522f0,), mem = 1.2596147f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 3500/3500, 00:15/00:15, 231.42i/s] (dev = 66.77254f0, tst = (13.354517f0,), mem = 1.2856596f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:11\n",
      "Ex.Generated words: sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโโโ                 โซ [11.11%, 1/9, 00:00/00:01, 16.61i/s] (dev = 22.869688f0, tst = (6.2656426f0,), mem = 1.294048f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 9/9, 00:00/00:00, 73.48i/s] (dev = 22.869211f0, tst = (6.2655206f0,), mem = 1.294048f10)\n",
      "\n",
      "โฃ                    โซ [0.10%, 1/1000, 00:00/02:28, 6.77i/s] (dev = 66.77254f0, tst = (13.354521f0,), mem = 1.294048f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 1000/1000, 00:05/00:05, 216.34i/s] (dev = 66.77254f0, tst = (13.354515f0,), mem = 1.2938333f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:12\n",
      "Ex.Generated words: sssss\n",
      "ssss\n",
      "LMppppp\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโโ                  โซ [7.69%, 1/13, 00:00/00:01, 19.86i/s] (dev = 22.869177f0, tst = (6.265517f0,), mem = 1.2947078f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 13/13, 00:00/00:00, 114.41i/s] (dev = 22.868805f0, tst = (6.26542f0,), mem = 1.2947078f10)\n",
      "\n",
      "โฃ                    โซ [0.07%, 1/1500, 00:00/03:24, 7.37i/s] (dev = 66.772545f0, tst = (13.354521f0,), mem = 1.2947078f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 1500/1500, 00:07/00:07, 229.17i/s] (dev = 66.77254f0, tst = (13.354521f0,), mem = 1.2946685f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:13\n",
      "Ex.Generated words: sssss\n",
      "ssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโ                   โซ [5.00%, 1/20, 00:00/00:01, 14.70i/s] (dev = 22.868761f0, tst = (6.26542f0,), mem = 1.2329929f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 20/20, 00:00/00:00, 136.29i/s] (dev = 22.868494f0, tst = (6.2653437f0,), mem = 1.2329931f10)\n",
      "\n",
      "โฃ                    โซ [0.03%, 1/3500, 00:00/07:44, 7.54i/s] (dev = 66.77254f0, tst = (13.354516f0,), mem = 1.2329931f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 3500/3500, 00:15/00:15, 233.87i/s] (dev = 66.77254f0, tst = (13.354517f0,), mem = 1.2152068f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:14\n",
      "Ex.Generated words: sssss\n",
      "ssss\n",
      "sssss\n",
      "sssss\n",
      "ssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโ                   โซ [4.55%, 1/22, 00:00/00:01, 15.69i/s] (dev = 22.86848f0, tst = (6.265337f0,), mem = 1.182465f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 22/22, 00:00/00:00, 149.43i/s] (dev = 22.86837f0, tst = (6.2653065f0,), mem = 1.18248f10)\n",
      "\n",
      "โฃ                    โซ [0.03%, 1/3000, 00:00/06:40, 7.49i/s] (dev = 66.77254f0, tst = (13.354519f0,), mem = 1.18248f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 3000/3000, 00:13/00:13, 233.11i/s] (dev = 66.77254f0, tst = (13.354515f0,), mem = 1.1727952f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:15\n",
      "Ex.Generated words: ssss\n",
      "ssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโ                   โซ [4.76%, 1/21, 00:00/00:01, 18.25i/s] (dev = 22.86838f0, tst = (6.2653117f0,), mem = 1.1648968f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 21/21, 00:00/00:00, 153.36i/s] (dev = 22.868309f0, tst = (6.265293f0,), mem = 1.1695121f10)\n",
      "\n",
      "โฃ                    โซ [0.02%, 1/4500, 00:00/10:25, 7.21i/s] (dev = 66.772545f0, tst = (13.354519f0,), mem = 1.1997636f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 4500/4500, 00:19/00:19, 233.19i/s] (dev = 66.77254f0, tst = (13.354515f0,), mem = 1.2653553f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:16\n",
      "Ex.Generated words: sssss\n",
      "sssss\n",
      "ssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโโโโ                โซ [20.00%, 1/5, 00:00/00:00, 18.55i/s] (dev = 22.868313f0, tst = (6.265289f0,), mem = 1.2763894f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 5/5, 00:00/00:00, 50.50i/s] (dev = 22.868296f0, tst = (6.265286f0,), mem = 1.2763894f10)\n",
      "\n",
      "โฃ                    โซ [0.02%, 1/4500, 00:00/10:08, 7.40i/s] (dev = 66.772545f0, tst = (13.35452f0,), mem = 1.2763894f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 4500/4500, 00:19/00:19, 235.02i/s] (dev = 66.77253f0, tst = (13.354515f0,), mem = 1.2763886f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:17\n",
      "Ex.Generated words: ssPPPP\n",
      "sssฤฐฤฐฤฐฤฐ\n",
      "ssssss\n",
      "sssss\n",
      "sICCCCC\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโโ                  โซ [5.88%, 1/17, 00:00/00:01, 20.54i/s] (dev = 22.868288f0, tst = (6.2652855f0,), mem = 1.2763887f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 17/17, 00:00/00:00, 141.52i/s] (dev = 22.868252f0, tst = (6.2652745f0,), mem = 1.2763887f10)\n",
      "\n",
      "โฃ                    โซ [0.02%, 1/5000, 00:00/11:23, 7.32i/s] (dev = 66.77254f0, tst = (13.354516f0,), mem = 1.2763887f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 5000/5000, 00:21/00:21, 235.22i/s] (dev = 66.77253f0, tst = (13.354514f0,), mem = 1.2763723f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:18\n",
      "Ex.Generated words: sssss\n",
      "ssssss\n",
      "ssssss\n",
      "sssssss\n",
      "\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโโโโ                โซ [16.67%, 1/6, 00:00/00:00, 17.34i/s] (dev = 22.86825f0, tst = (6.2652745f0,), mem = 1.2207516f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 6/6, 00:00/00:00, 57.11i/s] (dev = 22.868238f0, tst = (6.2652707f0,), mem = 1.2207516f10)\n",
      "\n",
      "โฃ                    โซ [0.03%, 1/4000, 00:00/08:02, 8.29i/s] (dev = 66.77253f0, tst = (13.354515f0,), mem = 1.2213275f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 4000/4000, 00:17/00:17, 229.33i/s] (dev = 66.77252f0, tst = (13.354513f0,), mem = 1.1957381f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:19\n",
      "Ex.Generated words: sssss\n",
      "sssssss\n",
      "ssลลttt\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโโโโ                โซ [20.00%, 1/5, 00:00/00:00, 16.48i/s] (dev = 22.868233f0, tst = (6.2652693f0,), mem = 1.1633609f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 5/5, 00:00/00:00, 47.24i/s] (dev = 22.868221f0, tst = (6.265267f0,), mem = 1.1633609f10)\n",
      "\n",
      "โฃ                    โซ [0.03%, 1/4000, 00:00/09:23, 7.10i/s] (dev = 66.77252f0, tst = (13.354513f0,), mem = 1.1633609f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 4000/4000, 00:17/00:17, 232.66i/s] (dev = 66.77252f0, tst = (13.354514f0,), mem = 1.170809f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:20\n",
      "Ex.Generated words: sssssss\n",
      "ssssss\n",
      "ssCCCCC\n",
      "ssssss\n",
      "ssลjjj\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "โฃโโ                  โซ [9.09%, 1/11, 00:00/00:01, 19.15i/s] (dev = 22.868221f0, tst = (6.2652655f0,), mem = 1.1719692f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 11/11, 00:00/00:00, 99.57i/s] (dev = 22.86821f0, tst = (6.2652626f0,), mem = 1.1719692f10)\n",
      "\n",
      "โฃ                    โซ [0.03%, 1/3000, 00:00/06:45, 7.41i/s] (dev = 66.77253f0, tst = (13.354513f0,), mem = 1.1719692f10)\n",
      "โฃโโโโโโโโโโโโโโโโโโโโโซ [100.00%, 3000/3000, 00:13/00:13, 233.76i/s] (dev = 66.77252f0, tst = (13.354513f0,), mem = 1.1703879f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n"
     ]
    }
   ],
   "source": [
    "function gmodel(epochs)\n",
    "    global genmodel\n",
    "    global BATCHSIZE\n",
    "    global MAXLENGTH\n",
    "    \n",
    "    ctrn = [ (Z(genmodel, BATCHSIZE, MAXLENGTH), 1) for i in 1:500 ]\n",
    "    trnxepoch = collect(flatten(shuffle!(ctrn) for i in 1:epochs))\n",
    "    trnmini = ctrn[1:20]\n",
    "    dev = [ (Z(genmodel, BATCHSIZE, MAXLENGTH), 1) for i in 1:100 ]\n",
    "    genmodel = train!(genmodel, params(genmodel)[1:2], trnxepoch, dev, trnmini)\n",
    "end\n",
    "\n",
    "function dmodel(batches)\n",
    "    global trnsampler\n",
    "    global devsampler\n",
    "    global dismodel\n",
    "    \n",
    "    ctrn = collect(trnsampler)\n",
    "    trnmini = ctrn[1:20]\n",
    "    ctrn = shuffle!(ctrn)[1:batches]\n",
    "    dev = collect(devsampler)\n",
    "    dismodel = train!(dismodel, params(dismodel), ctrn, dev, trnmini) \n",
    "end\n",
    "\n",
    "@info \"Started training...\"\n",
    "for k in 1:20\n",
    "    println(\"Turn no:\", k)\n",
    "    println(\"Ex.Generated words: \", join(generate(genmodel, MAXLENGTH, 5),\"\\n\"))\n",
    "\n",
    "    println(\"Training Discriminator:\")\n",
    "    dmodel(Int(ceil(rand() * 30)))\n",
    "    println(\"Training Generator:\")\n",
    "    gmodel(Int(ceil(rand() * 10)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ex.Generated words: lPjjjjj\n",
      "sssssss\n",
      "ssssss\n",
      "ssssss\n",
      "ssssss\n"
     ]
    }
   ],
   "source": [
    "println(\"Ex.Generated words: \", join(generate(genmodel, MAXLENGTH, 5),\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
