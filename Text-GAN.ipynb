{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-GAN Turkish word generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readwordset (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Knet, Test, Base.Iterators, Printf, LinearAlgebra, CuArrays, Random, IterTools, StatsBase\n",
    "\n",
    "struct Charset\n",
    "    c2i::Dict{Any,Int}\n",
    "    i2c::Vector{Any}\n",
    "    eow::Int\n",
    "end\n",
    "\n",
    "function Charset(charset::String; eow=\"\")\n",
    "    i2c = [ eow; [ c for c in charset ]  ]\n",
    "    print(i2c)\n",
    "    c2i = Dict( c => i for (i, c) in enumerate(i2c))\n",
    "    return Charset(c2i, i2c, c2i[eow])\n",
    "end\n",
    "\n",
    "struct TextReader\n",
    "    file::String\n",
    "    charset::Charset\n",
    "end\n",
    "\n",
    "function Base.iterate(r::TextReader, s=nothing)\n",
    "    s === nothing && (s = open(r.file))\n",
    "    eof(s) && return close(s)\n",
    "    return [ get(r.charset.c2i, c, r.charset.eow) for c in readline(s)], s\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{TextReader}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{TextReader}) = Base.HasEltype()\n",
    "Base.eltype(::Type{TextReader}) = Vector{Int}\n",
    "\n",
    "struct WordsData\n",
    "    src::TextReader        \n",
    "    batchsize::Int         \n",
    "    maxlength::Int         \n",
    "    batchmajor::Bool       \n",
    "    bucketwidth::Int    \n",
    "    buckets::Vector        \n",
    "end\n",
    "\n",
    "function WordsData(src::TextReader; batchsize = 128, maxlength = typemax(Int),\n",
    "                batchmajor = false, bucketwidth = 2, numbuckets = min(128, maxlength ÷ bucketwidth))\n",
    "    buckets = [ [] for i in 1:numbuckets ] # buckets[i] is an array of sentence pairs with similar length\n",
    "    WordsData(src, batchsize, maxlength, batchmajor, bucketwidth, buckets)\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{WordsData}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{WordsData}) = Base.HasEltype()\n",
    "Base.eltype(::Type{WordsData}) = NTuple{2}\n",
    "\n",
    "function Base.iterate(d::WordsData, state=nothing)\n",
    "    if state == 0 # When file is finished but buckets are partially full \n",
    "        for i in 1:length(d.buckets)\n",
    "            if length(d.buckets[i]) > 0\n",
    "                buc = d.buckets[i]\n",
    "                d.buckets[i] = []\n",
    "                return buc, state\n",
    "            end\n",
    "        end\n",
    "        return nothing # Finish iteration\n",
    "    end\n",
    "\n",
    "    while true\n",
    "        src_next = iterate(d.src, state)\n",
    "        \n",
    "        if src_next === nothing\n",
    "            state = 0\n",
    "            return iterate(d, state)\n",
    "        end\n",
    "        \n",
    "        (src_word, src_state) = src_next\n",
    "        state = src_state\n",
    "        src_length = length(src_word)\n",
    "        \n",
    "        (src_length > d.maxlength) && continue\n",
    "\n",
    "        i = Int(ceil(src_length / d.bucketwidth))\n",
    "        i > length(d.buckets) && (i = length(d.buckets))\n",
    "\n",
    "        push!(d.buckets[i], src_word)\n",
    "        if length(d.buckets[i]) == d.batchsize\n",
    "            buc = d.buckets[i]\n",
    "            d.buckets[i] = []\n",
    "            return buc, state\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function readwordset(fname)\n",
    "    words = []\n",
    "    fi = open(fname)\n",
    "    while !eof(fi)\n",
    "        push!(words, readline(fi))\n",
    "    end\n",
    "    close(fi)\n",
    "    words\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G/D Common Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Embed; w; end\n",
    "\n",
    "function Embed(shape...)\n",
    "    Embed(param(shape...))\n",
    "end\n",
    "\n",
    "# per-word loss (in this case per-batch loss)\n",
    "function loss(model, data; average=true)\n",
    "    l = 0\n",
    "    n = 0\n",
    "    a = 0\n",
    "    for (x, y) in data\n",
    "        v = model(x, y; average=false)\n",
    "        l += v[1]\n",
    "        n += v[2]\n",
    "        a += (v[1] / v[2])\n",
    "    end\n",
    "    average && return a\n",
    "    return l, n\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one to be used by DModel, takes weights of characters and reduce the embedding for each character\n",
    "# this approach to avoid sampling or argmaxing over rnn's output\n",
    "# (C, B, T) -> (T, E, 1, B)\n",
    "\n",
    "# function (l::Embed)(x)\n",
    "#     dims = size(x)\n",
    "#     em = l.w * reshape(x, dims[1], dims[2] * dims[3]) # reshape for multiplication \n",
    "#     em = reshape(em, size(em, 1), dims[2], dims[3]) # reshape to original size\n",
    "#     em = permutedims(em, [3, 1, 2])  # permute for CONV\n",
    "#     em = reshape(em, dims[3], size(em, 2), 1, dims[2]) # Add one dim for CONV\n",
    "# end\n",
    "\n",
    "# struct Conv; w; b; f; p; end\n",
    "# (c::Conv)(x) = (co=conv4(c.w, dropout(x,c.p)); c.f.(pool((co .+ c.b); window=(size(co, 1), size(co, 2)))))\n",
    "# Conv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)\n",
    "\n",
    "# struct Dense; w; b; f; p; end\n",
    "# (d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul\n",
    "# Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i), param0(o), f, pdrop)\n",
    "\n",
    "# # Perform convolution then, global-max pooling and concatenate the output and feed it to sequential dense layer \n",
    "# mutable struct DisModel\n",
    "#     charset::Charset\n",
    "#     embed::Embed\n",
    "#     filters\n",
    "#     dense_layers\n",
    "# end\n",
    "\n",
    "# # This discriminator uses separate weights for its embedding layer\n",
    "# function DisModel(charset, embeddingSize::Int, filters, denselayers)\n",
    "#     Em = Embed(embeddingSize, length(tr_charset.c2i))\n",
    "#     DisModel(charset, Em, filters, denselayers)\n",
    "# end\n",
    "\n",
    "# function (c::DisModel)(x) # the input here is weights of the characters with shape (C, B, T)\n",
    "#     em = c.embed(x)\n",
    "#     filters_out = []\n",
    "#     for f in c.filters\n",
    "#         push!(filters_out, f(em))\n",
    "#     end\n",
    "#     max_out = cat(filters_out...;dims=3)\n",
    "#     for l in c.dense_layers\n",
    "#         max_out = l(max_out)\n",
    "#     end\n",
    "#     max_out\n",
    "# end\n",
    "\n",
    "# (c::DisModel)(x,y; average=true) = nll(c(x), y; average=average)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (l::Embed)(x)\n",
    "    dims = size(x)\n",
    "    em = l.w * reshape(x, dims[1], dims[2] * dims[3]) # reshape for multiplication \n",
    "    em = reshape(em, size(em, 1), dims[2], dims[3]) # reshape to original size\n",
    "end\n",
    "\n",
    "struct Dense; w; b; f; p; end\n",
    "(d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 3-D tensor to 2-D matrix so we can use matmul\n",
    "Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i), param0(o), f, pdrop)\n",
    "\n",
    "mutable struct DisModel\n",
    "    charset::Charset\n",
    "    embed::Embed\n",
    "    rnn::RNN\n",
    "    denselayers\n",
    "end\n",
    "\n",
    "# This discriminator uses separate weights for its embedding layer\n",
    "function DisModel(charset, embeddingSize::Int, hidden, denselayers; layers=1, dropout=0)\n",
    "    Em = Embed(embeddingSize, length(tr_charset.c2i))\n",
    "    rnn = RNN(embeddingSize, hidden; numLayers=layers, dropout=dropout)\n",
    "    DisModel(charset, Em, rnn, denselayers)\n",
    "end\n",
    "\n",
    "function (c::DisModel)(x) # the input here is weights of the characters with shape (C, B, T)\n",
    "    c.rnn.h, c.rnn.c = 0, 0\n",
    "    em = c.embed(x)\n",
    "    rnn_out = permutedims(c.rnn(em), [1, 3, 2])\n",
    "    for l in c.denselayers\n",
    "        rnn_out = l(rnn_out)\n",
    "    end\n",
    "    rnn_out\n",
    "end\n",
    "\n",
    "(c::DisModel)(x,y; average=true) = nll(c(x), y; average=average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_z(shape...) = KnetArray(randn(Float32, shape...))\n",
    "\n",
    "### Not used \n",
    "# concatenate z with embedding vectors, z -> (z_size, B), returns (E+z_size, B, T)\n",
    "# this will be used to feed Z to generator at each timestep\n",
    "# function (l::Embed)(x, z)\n",
    "#     em = l.w[:, x]\n",
    "#     z_array = cat((z for i in 1:size(em, 3))...; dims=(3))\n",
    "#     cat(em, z_array; dims=(1))\n",
    "# end\n",
    "\n",
    "# Generator model\n",
    "struct GenModel\n",
    "    projection::Embed\n",
    "    rnn::RNN        \n",
    "    dropout::Real\n",
    "    charset::Charset\n",
    "    disModel::DisModel\n",
    "    maxlength::Int\n",
    "end\n",
    "\n",
    "function GenModel(inputsize::Int, hidden::Int, charset::Charset, disModel::DisModel, maxlength::Int; layers=2, dropout=0)\n",
    "    rnn = RNN(inputsize, hidden; numLayers=layers, dropout=dropout)\n",
    "    projection = Embed(hidden, length(charset.i2c))\n",
    "    GenModel(projection, rnn, dropout, charset, disModel, maxlength)\n",
    "end\n",
    "\n",
    "# This generator shares the projection layers weights of the discriminator for its projection layer\n",
    "function GenModel(inputsize::Int, charset::Charset, disModel::DisModel, maxlength::Int; layers=2, dropout=0)\n",
    "    rnn = RNN(inputsize, size(disModel.embed.w, 1); numLayers=layers, dropout=dropout)\n",
    "    GenModel(disModel.embed, rnn, dropout, charset, disModel, maxlength)\n",
    "end\n",
    "\n",
    "function Z(s::GenModel, batchsize, timesteps)\n",
    "    z = get_z(s.rnn.inputSize, batchsize, 1) # according to get_z(H, B, layers)\n",
    "    return cat([ z for i in 1:timesteps]...;dims=3)\n",
    "end\n",
    "\n",
    "# Generator forward pass, size(Z) -> inputsize, batchsize, sequencelength\n",
    "function (s::GenModel)(Z)\n",
    "    s.rnn.h, s.rnn.c = 0, 0\n",
    "    rnn_out = s.rnn(Z) \n",
    "    dims = size(rnn_out)\n",
    "    output = s.projection.w' * dropout(reshape(rnn_out, dims[1], dims[2] * dims[3]), s.dropout)\n",
    "    reshape(softmax(output), size(output, 1), dims[2], dims[3])\n",
    "end\n",
    "\n",
    "# Generator loss\n",
    "function (s::GenModel)(Z, calculateloss::Int; average=true)\n",
    "    y = Array(ones(Int, size(Z, 2))) # create labels 1 -> real, 2-> not-real\n",
    "    x = s(Z)\n",
    "    pads = KnetArray(zeros(Float32, size(x, 1), size(x, 2), s.maxlength - size(x, 3)))\n",
    "    pads[s.charset.eow, :, :] .= 1\n",
    "    x = cat(x, pads; dims=3) # padding\n",
    "    return s.disModel(x, y;average=average) \n",
    "end\n",
    "\n",
    "function generate(s::GenModel, maxlength, batchsize)\n",
    "    out = s(Z(s, batchsize, maxlength))\n",
    "    words = []\n",
    "    for i in 1:batchsize\n",
    "        push!(words, join([s.charset.i2c[x[1]] for x in argmax(out[:, i, :]; dims=1)], \"\"))\n",
    "    end\n",
    "    words\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word sampler will be used to train discriminator.\n",
    "this sampler should take B, T (batchsize, timestep) as parameters\n",
    "returns (X, Y) tuple \n",
    "where X is tensor of size (C, B, T)\n",
    "and Y is array of size B\n",
    "B consists of real words and generated words\n",
    "C charset size where each value is weight of this char\n",
    "in the case of generated words the generator already gives C, B, T\n",
    "for real words we need to convert words to C, T arrays\n",
    "where every character can be represented by one hot vector or by Gumble-Max (which is normalized one hot vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Sampler\n",
    "    wordsdata::WordsData\n",
    "    charset::Charset\n",
    "    genModel::GenModel\n",
    "    maxBatchsize::Int\n",
    "end\n",
    "\n",
    "# this function is similar to gumble softmax, it is used to soften the one-hot-vector of the real samples\n",
    "# tau -> normalization factor; the bigger the softer\n",
    "function soften(A; dims=1, tau=2.0) \n",
    "    A = A ./ tau\n",
    "    softmax(A; dims=dims)\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{Sampler}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{Sampler}) = Base.HasEltype()\n",
    "Base.eltype(::Type{Sampler}) = Tuple{KnetArray{Float32,3},Array{Int64,1}}\n",
    "\n",
    "function Base.iterate(s::Sampler, state=nothing)\n",
    "    wdatastate = iterate(s.wordsdata, state)\n",
    "    wdatastate === nothing && (return nothing)\n",
    "    \n",
    "    (bucket, state) = wdatastate\n",
    "    bsize = length(bucket)\n",
    "    src_eow = s.charset.eow\n",
    "    src_lengths = map(x -> length(x), bucket)\n",
    "    max_length = max(src_lengths...)\n",
    "    gsize = 1 + rand(bsize:s.maxBatchsize) - bsize # count of words to be generated\n",
    "    generated = s.genModel(Z(s.genModel, gsize, max_length))\n",
    "\n",
    "    to_be_cat = [generated, ]\n",
    "    for (i, v) in enumerate(bucket)\n",
    "        tindex = [i for i in 1:length(v)]\n",
    "        onehot = KnetArray(zeros(Float32, length(s.charset.c2i), 1, max_length))\n",
    "        onehot[v, :, tindex] .= 1\n",
    "        onehot = soften(onehot) # soften one hot vectors elements value\n",
    "        push!(to_be_cat, onehot)\n",
    "    end\n",
    "    x = cat(to_be_cat...;dims=2) # concatenate both generated and sampled words\n",
    "    pads = KnetArray(zeros(Float32, size(x, 1), size(x, 2), s.wordsdata.maxlength - size(x, 3)))\n",
    "    pads[s.charset.eow, :, :] .= 1\n",
    "    \n",
    "#     pads = soften(pads) # getting error \n",
    "\n",
    "    x = cat(x, pads; dims=3) # padding\n",
    "    y = Array(ones(Int, gsize+bsize)) # create labels 1 -> real, 2-> not-real\n",
    "    y[1:gsize] = y[1:gsize] .+ 1\n",
    "    \n",
    "    ind = shuffle(1:gsize+bsize) # used to shuffle the batch\n",
    "    x, y = x[:, ind, :], y[ind]\n",
    "    return (x,y), state\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train! (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train!(model, parameters, trn, dev, tst...)\n",
    "    bestmodel, bestloss = deepcopy(model), loss(model, dev)\n",
    "    progress!(adam(model, trn; params=parameters), seconds=30) do y\n",
    "        devloss = loss(model, dev)\n",
    "        tstloss = map(d->loss(model,d), tst)\n",
    "        if devloss < bestloss\n",
    "            bestloss, bestmodel = devloss, deepcopy(model)\n",
    "        end\n",
    "        println(stderr)\n",
    "        (dev=devloss, tst=tstloss, mem=Float32(CuArrays.usage[]))\n",
    "    end\n",
    "    return bestmodel\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-word loss (in this case per-batch loss)\n",
    "function loss(model, data; average=true)\n",
    "    l = 0\n",
    "    n = 0\n",
    "    a = 0\n",
    "    for (x, y) in data\n",
    "        v = model(x, y; average=false)\n",
    "        l += v[1]\n",
    "        n += v[2]\n",
    "        a += (v[1] / v[2])\n",
    "    end\n",
    "    average && return a\n",
    "    return l, n\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'y', 'z', 'Ç', 'Ö', 'Ü', 'ç', 'ö', 'ü', 'Ğ', 'ğ', 'İ', 'ı', 'Ş', 'ş']"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WordsData(TextReader(\"turkish_word_set/dev.tr\", Charset(Dict{Any,Int64}('ç' => 51,'Ğ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ğ' => 55…), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  …  'Ü', 'ç', 'ö', 'ü', 'Ğ', 'ğ', 'İ', 'ı', 'Ş', 'ş'], 1)), 128, 7, false, 1, Array{Any,1}[[], [], [], [], [], [], []])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_set = \"ABCDEFGHIJKLMNOPRSTUVYZabcdefghijklmnoprstuvyzÇÖÜçöüĞğİıŞş\"\n",
    "tr_charset = Charset(char_set)\n",
    "datadir = \"turkish_word_set\"\n",
    "BATCHSIZE = 128\n",
    "MAXLENGTH = 7\n",
    "tr_dev = TextReader(\"$datadir/dev.tr\", tr_charset)\n",
    "tr_trn = TextReader(\"$datadir/train.tr\", tr_charset)\n",
    "dtrn = WordsData(tr_trn, batchsize=BATCHSIZE, maxlength=MAXLENGTH, bucketwidth = 1)\n",
    "ddev = WordsData(tr_dev, batchsize=BATCHSIZE, maxlength=MAXLENGTH, bucketwidth = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sampler(WordsData(TextReader(\"turkish_word_set/dev.tr\", Charset(Dict{Any,Int64}('ç' => 51,'Ğ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ğ' => 55…), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  …  'Ü', 'ç', 'ö', 'ü', 'Ğ', 'ğ', 'İ', 'ı', 'Ş', 'ş'], 1)), 128, 7, false, 1, Array{Any,1}[[], [], [], [], [], [], []]), Charset(Dict{Any,Int64}('ç' => 51,'Ğ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ğ' => 55…), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  …  'Ü', 'ç', 'ö', 'ü', 'Ğ', 'ğ', 'İ', 'ı', 'Ş', 'ş'], 1), GenModel(Embed(P(KnetArray{Float32,2}(256,59))), LSTM(input=128,hidden=256,layers=2,dropout=0.2), 0.2, Charset(Dict{Any,Int64}('ç' => 51,'Ğ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ğ' => 55…), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  …  'Ü', 'ç', 'ö', 'ü', 'Ğ', 'ğ', 'İ', 'ı', 'Ş', 'ş'], 1), DisModel(Charset(Dict{Any,Int64}('ç' => 51,'Ğ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ğ' => 55…), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  …  'Ü', 'ç', 'ö', 'ü', 'Ğ', 'ğ', 'İ', 'ı', 'Ş', 'ş'], 1), Embed(P(KnetArray{Float32,2}(64,59))), LSTM(input=64,hidden=128,dropout=0.2), (Dense(P(KnetArray{Float32,2}(16,896)), P(KnetArray{Float32,1}(16)), NNlib.relu, 0.2), Dense(P(KnetArray{Float32,2}(2,16)), P(KnetArray{Float32,1}(2)), Knet.sigm, 0.2))), 7), 256)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 64\n",
    "DHIDDEN_SIZE = 128\n",
    "GDROPOUT = 0.2\n",
    "DDROPOUT = 0.2\n",
    "\n",
    "dismodel = DisModel(tr_charset, EMBEDDING_SIZE, DHIDDEN_SIZE,(\n",
    "        Dense(DHIDDEN_SIZE * MAXLENGTH, 16, pdrop=DDROPOUT),\n",
    "        Dense(16, 2, sigm, pdrop=0.2)\n",
    "        ); dropout=DDROPOUT)\n",
    "\n",
    "GE_SIZE = 256\n",
    "Z_SIZE = 128\n",
    "\n",
    "genmodel = GenModel(Z_SIZE, GE_SIZE, tr_charset, dismodel, MAXLENGTH; dropout=GDROPOUT, layers=2)\n",
    "trnsampler = Sampler(dtrn, tr_charset, genmodel, BATCHSIZE * 2)\n",
    "devsampler = Sampler(ddev, tr_charset, genmodel, BATCHSIZE * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Started training...\n",
      "└ @ Main In[29]:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn no:1\n",
      "Ex.Generated words: VVVVVVV\n",
      "ÖÖÖkkkk\n",
      "ttççççç\n",
      "İİbbbbb\n",
      "vvvvvİİ\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣██                  ┫ [10.00%, 1/10, 00:00/00:01, 10.64i/s] (dev = 50.550514f0, tst = (13.850113f0,), mem = 2.8813647f9)\n",
      "┣████████████████████┫ [100.00%, 10/10, 00:00/00:00, 65.72i/s] (dev = 49.052547f0, tst = (13.487146f0,), mem = 2.8834696f9)\n",
      "\n",
      "┣                    ┫ [0.10%, 1/1000, 00:00/03:56, 4.24i/s] (dev = 66.78007f0, tst = (13.356004f0,), mem = 7.971089f9)\n",
      "┣████████████████████┫ [100.00%, 1000/1000, 00:05/00:05, 194.71i/s] (dev = 66.772545f0, tst = (13.354519f0,), mem = 1.3836291f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:2\n",
      "Ex.Generated words: sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣█▊                  ┫ [9.09%, 1/11, 00:00/00:01, 19.76i/s] (dev = 48.73716f0, tst = (13.2623825f0,), mem = 1.3836448f10)\n",
      "┣███████████████████▉┫ [100.00%, 11/11, 00:00/00:00, 100.53i/s] (dev = 42.06518f0, tst = (11.030857f0,), mem = 1.3836448f10)\n",
      "\n",
      "┣                    ┫ [0.03%, 1/3000, 00:00/06:59, 7.15i/s] (dev = 66.772545f0, tst = (13.354521f0,), mem = 1.3836448f10)\n",
      "┣████████████████████┫ [100.00%, 3000/3000, 00:13/00:13, 230.44i/s] (dev = 66.772545f0, tst = (13.35452f0,), mem = 1.3937111f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:3\n",
      "Ex.Generated words: ssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "ssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣██                  ┫ [10.00%, 1/10, 00:00/00:01, 19.82i/s] (dev = 40.685947f0, tst = (10.366326f0,), mem = 1.3937127f10)\n",
      "┣████████████████████┫ [100.00%, 10/10, 00:00/00:00, 93.19i/s] (dev = 36.221367f0, tst = (9.186247f0,), mem = 1.3937127f10)\n",
      "\n",
      "┣                    ┫ [0.05%, 1/2000, 00:00/04:30, 7.40i/s] (dev = 66.77254f0, tst = (13.354519f0,), mem = 1.3937127f10)\n",
      "┣████████████████████┫ [100.00%, 2000/2000, 00:09/00:09, 230.89i/s] (dev = 66.77254f0, tst = (13.354516f0,), mem = 1.3812986f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:4\n",
      "Ex.Generated words: sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣██▊                 ┫ [14.29%, 1/7, 00:00/00:01, 13.22i/s] (dev = 34.70887f0, tst = (9.379989f0,), mem = 1.1734063f10)\n",
      "┣████████████████████┫ [100.00%, 7/7, 00:00/00:00, 55.55i/s] (dev = 31.616816f0, tst = (8.5753355f0,), mem = 1.1734063f10)\n",
      "\n",
      "┣                    ┫ [0.02%, 1/4500, 00:00/10:08, 7.41i/s] (dev = 66.77254f0, tst = (13.354519f0,), mem = 1.2110756f10)\n",
      "┣████████████████████┫ [100.00%, 4500/4500, 00:19/00:19, 234.54i/s] (dev = 66.77254f0, tst = (13.354523f0,), mem = 1.186733f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:5\n",
      "Ex.Generated words: sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣██▏                 ┫ [11.11%, 1/9, 00:00/00:01, 15.76i/s] (dev = 33.15883f0, tst = (8.8484955f0,), mem = 1.1950488f10)\n",
      "┣███████████████████▉┫ [100.00%, 9/9, 00:00/00:00, 76.54i/s] (dev = 31.002481f0, tst = (8.33415f0,), mem = 1.1950488f10)\n",
      "\n",
      "┣                    ┫ [0.03%, 1/3500, 00:00/08:49, 6.62i/s] (dev = 66.77254f0, tst = (13.354519f0,), mem = 1.249365f10)\n",
      "┣████████████████████┫ [100.00%, 3500/3500, 00:16/00:16, 223.44i/s] (dev = 66.77254f0, tst = (13.354515f0,), mem = 1.2678703f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:6\n",
      "Ex.Generated words: sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣▉                   ┫ [4.55%, 1/22, 00:00/00:01, 19.10i/s] (dev = 30.788013f0, tst = (8.158402f0,), mem = 1.2678742f10)\n",
      "┣███████████████████▉┫ [100.00%, 22/22, 00:00/00:00, 162.11i/s] (dev = 23.03034f0, tst = (6.305452f0,), mem = 1.2678745f10)\n",
      "\n",
      "┣                    ┫ [0.03%, 1/3000, 00:00/06:41, 7.48i/s] (dev = 66.77254f0, tst = (13.35452f0,), mem = 1.2678745f10)\n",
      "┣████████████████████┫ [100.00%, 3000/3000, 00:13/00:13, 233.50i/s] (dev = 66.77254f0, tst = (13.354517f0,), mem = 1.2712197f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:7\n",
      "Ex.Generated words: sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣█                   ┫ [5.00%, 1/20, 00:00/00:01, 20.65i/s] (dev = 22.986294f0, tst = (6.2994094f0,), mem = 1.2712283f10)\n",
      "┣████████████████████┫ [100.00%, 20/20, 00:00/00:00, 158.17i/s] (dev = 22.87265f0, tst = (6.266535f0,), mem = 1.2712287f10)\n",
      "\n",
      "┣                    ┫ [0.04%, 1/2500, 00:00/05:36, 7.44i/s] (dev = 66.77254f0, tst = (13.354517f0,), mem = 1.2712287f10)\n",
      "┣████████████████████┫ [100.00%, 2500/2500, 00:11/00:11, 229.38i/s] (dev = 66.77254f0, tst = (13.354517f0,), mem = 1.3570786f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:8\n",
      "Ex.Generated words: sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣██▍                 ┫ [12.50%, 1/8, 00:00/00:01, 14.38i/s] (dev = 22.87233f0, tst = (6.2662687f0,), mem = 1.3093236f10)\n",
      "┣███████████████████▉┫ [100.00%, 8/8, 00:00/00:00, 65.77i/s] (dev = 22.870625f0, tst = (6.2658606f0,), mem = 1.3093236f10)\n",
      "\n",
      "┣                    ┫ [0.10%, 1/1000, 00:00/02:19, 7.22i/s] (dev = 66.77254f0, tst = (13.354521f0,), mem = 1.3093236f10)\n",
      "┣████████████████████┫ [100.00%, 1000/1000, 00:04/00:04, 223.59i/s] (dev = 66.772545f0, tst = (13.35452f0,), mem = 1.2718644f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:9\n",
      "Ex.Generated words: sssss\n",
      "ssss\n",
      "sssss\n",
      "ssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣██▍                 ┫ [12.50%, 1/8, 00:00/00:00, 17.38i/s] (dev = 22.870375f0, tst = (6.265909f0,), mem = 1.2485471f10)\n",
      "┣███████████████████▉┫ [100.00%, 8/8, 00:00/00:00, 69.94i/s] (dev = 22.869791f0, tst = (6.265723f0,), mem = 1.2485471f10)\n",
      "\n",
      "┣                    ┫ [0.02%, 1/4500, 00:00/10:19, 7.27i/s] (dev = 66.77254f0, tst = (13.354523f0,), mem = 1.297437f10)\n",
      "┣████████████████████┫ [100.00%, 4500/4500, 00:20/00:20, 227.17i/s] (dev = 66.77254f0, tst = (13.354514f0,), mem = 1.3106704f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:10\n",
      "Ex.Generated words: ssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣███████████████████▉┫ [100.00%, 1/1, 00:00/00:00, 16.86i/s] (dev = 22.869762f0, tst = (6.265684f0,), mem = 1.2219184f10)\n",
      "┣███████████████████▉┫ [100.00%, 1/1, 00:00/00:00, 10.50i/s] (dev = 22.869762f0, tst = (6.265684f0,), mem = 1.2219184f10)\n",
      "\n",
      "┣                    ┫ [0.03%, 1/3500, 00:00/08:05, 7.22i/s] (dev = 66.77254f0, tst = (13.354522f0,), mem = 1.2596147f10)\n",
      "┣████████████████████┫ [100.00%, 3500/3500, 00:15/00:15, 231.42i/s] (dev = 66.77254f0, tst = (13.354517f0,), mem = 1.2856596f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:11\n",
      "Ex.Generated words: sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣██▏                 ┫ [11.11%, 1/9, 00:00/00:01, 16.61i/s] (dev = 22.869688f0, tst = (6.2656426f0,), mem = 1.294048f10)\n",
      "┣███████████████████▉┫ [100.00%, 9/9, 00:00/00:00, 73.48i/s] (dev = 22.869211f0, tst = (6.2655206f0,), mem = 1.294048f10)\n",
      "\n",
      "┣                    ┫ [0.10%, 1/1000, 00:00/02:28, 6.77i/s] (dev = 66.77254f0, tst = (13.354521f0,), mem = 1.294048f10)\n",
      "┣████████████████████┫ [100.00%, 1000/1000, 00:05/00:05, 216.34i/s] (dev = 66.77254f0, tst = (13.354515f0,), mem = 1.2938333f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:12\n",
      "Ex.Generated words: sssss\n",
      "ssss\n",
      "LMppppp\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣█▌                  ┫ [7.69%, 1/13, 00:00/00:01, 19.86i/s] (dev = 22.869177f0, tst = (6.265517f0,), mem = 1.2947078f10)\n",
      "┣███████████████████▉┫ [100.00%, 13/13, 00:00/00:00, 114.41i/s] (dev = 22.868805f0, tst = (6.26542f0,), mem = 1.2947078f10)\n",
      "\n",
      "┣                    ┫ [0.07%, 1/1500, 00:00/03:24, 7.37i/s] (dev = 66.772545f0, tst = (13.354521f0,), mem = 1.2947078f10)\n",
      "┣████████████████████┫ [100.00%, 1500/1500, 00:07/00:07, 229.17i/s] (dev = 66.77254f0, tst = (13.354521f0,), mem = 1.2946685f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:13\n",
      "Ex.Generated words: sssss\n",
      "ssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣█                   ┫ [5.00%, 1/20, 00:00/00:01, 14.70i/s] (dev = 22.868761f0, tst = (6.26542f0,), mem = 1.2329929f10)\n",
      "┣████████████████████┫ [100.00%, 20/20, 00:00/00:00, 136.29i/s] (dev = 22.868494f0, tst = (6.2653437f0,), mem = 1.2329931f10)\n",
      "\n",
      "┣                    ┫ [0.03%, 1/3500, 00:00/07:44, 7.54i/s] (dev = 66.77254f0, tst = (13.354516f0,), mem = 1.2329931f10)\n",
      "┣████████████████████┫ [100.00%, 3500/3500, 00:15/00:15, 233.87i/s] (dev = 66.77254f0, tst = (13.354517f0,), mem = 1.2152068f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:14\n",
      "Ex.Generated words: sssss\n",
      "ssss\n",
      "sssss\n",
      "sssss\n",
      "ssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣▉                   ┫ [4.55%, 1/22, 00:00/00:01, 15.69i/s] (dev = 22.86848f0, tst = (6.265337f0,), mem = 1.182465f10)\n",
      "┣███████████████████▉┫ [100.00%, 22/22, 00:00/00:00, 149.43i/s] (dev = 22.86837f0, tst = (6.2653065f0,), mem = 1.18248f10)\n",
      "\n",
      "┣                    ┫ [0.03%, 1/3000, 00:00/06:40, 7.49i/s] (dev = 66.77254f0, tst = (13.354519f0,), mem = 1.18248f10)\n",
      "┣████████████████████┫ [100.00%, 3000/3000, 00:13/00:13, 233.11i/s] (dev = 66.77254f0, tst = (13.354515f0,), mem = 1.1727952f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:15\n",
      "Ex.Generated words: ssss\n",
      "ssss\n",
      "sssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣▉                   ┫ [4.76%, 1/21, 00:00/00:01, 18.25i/s] (dev = 22.86838f0, tst = (6.2653117f0,), mem = 1.1648968f10)\n",
      "┣███████████████████▉┫ [100.00%, 21/21, 00:00/00:00, 153.36i/s] (dev = 22.868309f0, tst = (6.265293f0,), mem = 1.1695121f10)\n",
      "\n",
      "┣                    ┫ [0.02%, 1/4500, 00:00/10:25, 7.21i/s] (dev = 66.772545f0, tst = (13.354519f0,), mem = 1.1997636f10)\n",
      "┣████████████████████┫ [100.00%, 4500/4500, 00:19/00:19, 233.19i/s] (dev = 66.77254f0, tst = (13.354515f0,), mem = 1.2653553f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:16\n",
      "Ex.Generated words: sssss\n",
      "sssss\n",
      "ssss\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣████                ┫ [20.00%, 1/5, 00:00/00:00, 18.55i/s] (dev = 22.868313f0, tst = (6.265289f0,), mem = 1.2763894f10)\n",
      "┣████████████████████┫ [100.00%, 5/5, 00:00/00:00, 50.50i/s] (dev = 22.868296f0, tst = (6.265286f0,), mem = 1.2763894f10)\n",
      "\n",
      "┣                    ┫ [0.02%, 1/4500, 00:00/10:08, 7.40i/s] (dev = 66.772545f0, tst = (13.35452f0,), mem = 1.2763894f10)\n",
      "┣████████████████████┫ [100.00%, 4500/4500, 00:19/00:19, 235.02i/s] (dev = 66.77253f0, tst = (13.354515f0,), mem = 1.2763886f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:17\n",
      "Ex.Generated words: ssPPPP\n",
      "sssİİİİ\n",
      "ssssss\n",
      "sssss\n",
      "sICCCCC\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣█▏                  ┫ [5.88%, 1/17, 00:00/00:01, 20.54i/s] (dev = 22.868288f0, tst = (6.2652855f0,), mem = 1.2763887f10)\n",
      "┣████████████████████┫ [100.00%, 17/17, 00:00/00:00, 141.52i/s] (dev = 22.868252f0, tst = (6.2652745f0,), mem = 1.2763887f10)\n",
      "\n",
      "┣                    ┫ [0.02%, 1/5000, 00:00/11:23, 7.32i/s] (dev = 66.77254f0, tst = (13.354516f0,), mem = 1.2763887f10)\n",
      "┣████████████████████┫ [100.00%, 5000/5000, 00:21/00:21, 235.22i/s] (dev = 66.77253f0, tst = (13.354514f0,), mem = 1.2763723f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:18\n",
      "Ex.Generated words: sssss\n",
      "ssssss\n",
      "ssssss\n",
      "sssssss\n",
      "\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣███▎                ┫ [16.67%, 1/6, 00:00/00:00, 17.34i/s] (dev = 22.86825f0, tst = (6.2652745f0,), mem = 1.2207516f10)\n",
      "┣████████████████████┫ [100.00%, 6/6, 00:00/00:00, 57.11i/s] (dev = 22.868238f0, tst = (6.2652707f0,), mem = 1.2207516f10)\n",
      "\n",
      "┣                    ┫ [0.03%, 1/4000, 00:00/08:02, 8.29i/s] (dev = 66.77253f0, tst = (13.354515f0,), mem = 1.2213275f10)\n",
      "┣████████████████████┫ [100.00%, 4000/4000, 00:17/00:17, 229.33i/s] (dev = 66.77252f0, tst = (13.354513f0,), mem = 1.1957381f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:19\n",
      "Ex.Generated words: sssss\n",
      "sssssss\n",
      "ssşşttt\n",
      "sssss\n",
      "sssss\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣████                ┫ [20.00%, 1/5, 00:00/00:00, 16.48i/s] (dev = 22.868233f0, tst = (6.2652693f0,), mem = 1.1633609f10)\n",
      "┣████████████████████┫ [100.00%, 5/5, 00:00/00:00, 47.24i/s] (dev = 22.868221f0, tst = (6.265267f0,), mem = 1.1633609f10)\n",
      "\n",
      "┣                    ┫ [0.03%, 1/4000, 00:00/09:23, 7.10i/s] (dev = 66.77252f0, tst = (13.354513f0,), mem = 1.1633609f10)\n",
      "┣████████████████████┫ [100.00%, 4000/4000, 00:17/00:17, 232.66i/s] (dev = 66.77252f0, tst = (13.354514f0,), mem = 1.170809f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n",
      "Turn no:20\n",
      "Ex.Generated words: sssssss\n",
      "ssssss\n",
      "ssCCCCC\n",
      "ssssss\n",
      "ssşjjj\n",
      "Training Generator:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "┣█▊                  ┫ [9.09%, 1/11, 00:00/00:01, 19.15i/s] (dev = 22.868221f0, tst = (6.2652655f0,), mem = 1.1719692f10)\n",
      "┣███████████████████▉┫ [100.00%, 11/11, 00:00/00:00, 99.57i/s] (dev = 22.86821f0, tst = (6.2652626f0,), mem = 1.1719692f10)\n",
      "\n",
      "┣                    ┫ [0.03%, 1/3000, 00:00/06:45, 7.41i/s] (dev = 66.77253f0, tst = (13.354513f0,), mem = 1.1719692f10)\n",
      "┣████████████████████┫ [100.00%, 3000/3000, 00:13/00:13, 233.76i/s] (dev = 66.77252f0, tst = (13.354513f0,), mem = 1.1703879f10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Discriminator:\n"
     ]
    }
   ],
   "source": [
    "function gmodel(epochs)\n",
    "    global genmodel\n",
    "    global BATCHSIZE\n",
    "    global MAXLENGTH\n",
    "    \n",
    "    ctrn = [ (Z(genmodel, BATCHSIZE, MAXLENGTH), 1) for i in 1:500 ]\n",
    "    trnxepoch = collect(flatten(shuffle!(ctrn) for i in 1:epochs))\n",
    "    trnmini = ctrn[1:20]\n",
    "    dev = [ (Z(genmodel, BATCHSIZE, MAXLENGTH), 1) for i in 1:100 ]\n",
    "    genmodel = train!(genmodel, params(genmodel)[1:2], trnxepoch, dev, trnmini)\n",
    "end\n",
    "\n",
    "function dmodel(batches)\n",
    "    global trnsampler\n",
    "    global devsampler\n",
    "    global dismodel\n",
    "    \n",
    "    ctrn = collect(trnsampler)\n",
    "    trnmini = ctrn[1:20]\n",
    "    ctrn = shuffle!(ctrn)[1:batches]\n",
    "    dev = collect(devsampler)\n",
    "    dismodel = train!(dismodel, params(dismodel), ctrn, dev, trnmini) \n",
    "end\n",
    "\n",
    "@info \"Started training...\"\n",
    "for k in 1:20\n",
    "    println(\"Turn no:\", k)\n",
    "    println(\"Ex.Generated words: \", join(generate(genmodel, MAXLENGTH, 5),\"\\n\"))\n",
    "\n",
    "    println(\"Training Discriminator:\")\n",
    "    dmodel(Int(ceil(rand() * 30)))\n",
    "    println(\"Training Generator:\")\n",
    "    gmodel(Int(ceil(rand() * 10)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ex.Generated words: lPjjjjj\n",
      "sssssss\n",
      "ssssss\n",
      "ssssss\n",
      "ssssss\n"
     ]
    }
   ],
   "source": [
    "println(\"Ex.Generated words: \", join(generate(genmodel, MAXLENGTH, 5),\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
