{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turkish Words Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet, Test, Base.Iterators, Printf, LinearAlgebra, CuArrays, Random, IterTools, StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arraybatch (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Charset\n",
    "    c2i::Dict{Any,Int}\n",
    "    i2c::Vector{Any}\n",
    "    eow::Int\n",
    "end\n",
    "\n",
    "function Charset(charset::String; eow=\"\")\n",
    "    i2c = [ eow; [ c for c in charset ]  ]\n",
    "    c2i = Dict( c => i for (i, c) in enumerate(i2c))\n",
    "    return Charset(c2i, i2c, c2i[eow])\n",
    "end\n",
    "\n",
    "struct TextReader\n",
    "    file::String\n",
    "    charset::Charset\n",
    "end\n",
    "\n",
    "function Base.iterate(r::TextReader, s=nothing)\n",
    "    s === nothing && (s = open(r.file))\n",
    "    eof(s) && return close(s)\n",
    "    word, label = split(readline(s))\n",
    "    return (([ get(r.charset.c2i, c, r.charset.eow) for c in word ], parse(Int, label) + 1), s)\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{TextReader}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{TextReader}) = Base.HasEltype()\n",
    "Base.eltype(::Type{TextReader}) = Vector{Int}\n",
    "\n",
    "struct WordsData\n",
    "    src::TextReader        \n",
    "    batchsize::Int         \n",
    "    maxlength::Int         \n",
    "    batchmajor::Bool       \n",
    "    bucketwidth::Int    \n",
    "    buckets::Vector        \n",
    "    batchmaker::Function   \n",
    "end\n",
    "\n",
    "function WordsData(src::TextReader; batchmaker = arraybatch, batchsize = 128, maxlength = typemax(Int),\n",
    "                batchmajor = false, bucketwidth = 2, numbuckets = min(128, maxlength ÷ bucketwidth))\n",
    "    buckets = [ [] for i in 1:numbuckets ] # buckets[i] is an array of sentence pairs with similar length\n",
    "    WordsData(src, batchsize, maxlength, batchmajor, bucketwidth, buckets, batchmaker)\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{WordsData}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{WordsData}) = Base.HasEltype()\n",
    "Base.eltype(::Type{WordsData}) = Tuple{Array{Int64,2},Array{Int64,1}}\n",
    "\n",
    "function Base.iterate(d::WordsData, state=nothing)\n",
    "    if state == 0 # When file is finished but buckets are partially full \n",
    "        for i in 1:length(d.buckets)\n",
    "            if length(d.buckets[i]) > 0\n",
    "                batch = d.batchmaker(d, d.buckets[i])\n",
    "                d.buckets[i] = []\n",
    "                return batch, state\n",
    "            end\n",
    "        end\n",
    "        return nothing # Finish iteration\n",
    "    elseif state === nothing\n",
    "        # Just to make sure\n",
    "        for i in 1:length(d.buckets)\n",
    "            d.buckets[i] = []\n",
    "        end\n",
    "        state = nothing\n",
    "    end\n",
    "\n",
    "    while true\n",
    "        src_next = iterate(d.src, state)\n",
    "        \n",
    "        if src_next === nothing\n",
    "            state = 0\n",
    "            return iterate(d, state)\n",
    "        end\n",
    "        \n",
    "        (src_word, src_state) = src_next\n",
    "        state = src_state\n",
    "        src_length = length(src_word[1])\n",
    "        \n",
    "        (src_length > d.maxlength) && continue\n",
    "\n",
    "        i = Int(ceil(src_length / d.bucketwidth))\n",
    "        i > length(d.buckets) && (i = length(d.buckets))\n",
    "\n",
    "        push!(d.buckets[i], src_word)\n",
    "        if length(d.buckets[i]) == d.batchsize\n",
    "            batch = d.batchmaker(d, d.buckets[i])\n",
    "            d.buckets[i] = []\n",
    "            return batch, state\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function arraybatch(d::WordsData, bucket)\n",
    "    src_eow = d.src.charset.eow\n",
    "    \n",
    "    x = zeros(Int64, length(bucket), d.maxlength) # default d.batchmajor is false\n",
    "    for (i, v) in enumerate(bucket)\n",
    "        to_be_added = fill(src_eow, d.maxlength - length(v[1]))\n",
    "        x[i,:] = [v[1]; to_be_added]\n",
    "    end\n",
    "    \n",
    "    y = [ x[2] for x in bucket]\n",
    "    \n",
    "    d.batchmajor && (x = x')\n",
    "    return (x, y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Reading data\n",
      "└ @ Main In[3]:5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WordsData(TextReader(\"discriminator_labeled_set/dis.dev\", Charset(Dict{Any,Int64}('ç' => 51,'Ğ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ğ' => 55…), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  …  'Ü', 'ç', 'ö', 'ü', 'Ğ', 'ğ', 'İ', 'ı', 'Ş', 'ş'], 1)), 32, 25, false, 1, Array{Any,1}[[], [], [], [], [], [], [], [], [], []  …  [], [], [], [], [], [], [], [], [], []], arraybatch)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_set = \"ABCDEFGHIJKLMNOPRSTUVYZabcdefghijklmnoprstuvyzÇÖÜçöüĞğİıŞş\"\n",
    "datadir = \"discriminator_labeled_set\"\n",
    "\n",
    "BATCHSIZE, MAXLENGTH = 32, 25\n",
    "@info \"Reading data\"\n",
    "tr_charset = Charset(char_set)\n",
    "tr_train = TextReader(\"$datadir/dis.train\", tr_charset)\n",
    "tr_dev = TextReader(\"$datadir/dis.dev\", tr_charset)\n",
    "dtrn = WordsData(tr_train, batchsize=BATCHSIZE, maxlength=MAXLENGTH, bucketwidth = 1)\n",
    "ddev = WordsData(tr_dev, batchsize=BATCHSIZE, maxlength=MAXLENGTH, bucketwidth = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Embed; w; end\n",
    "Embed(charsetsize::Int, embedsize::Int) = Embed(param(embedsize, charsetsize))\n",
    "(l::Embed)(x) = (em=permutedims(l.w[:, x], [3, 1, 2]); ds=size(em); em=reshape(em, ds[1], ds[2], 1, ds[3])) # (E, B, T) -> (T, E, 1, B)\n",
    "\n",
    "struct Conv; w; b; f; p; end\n",
    "(c::Conv)(x) = (co=conv4(c.w, dropout(x,c.p)); c.f.(pool((co .+ c.b); window=(size(x, 1), size(x, 2)))))\n",
    "Conv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)\n",
    "\n",
    "struct Dense; w; b; f; p; end\n",
    "(d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul\n",
    "Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i), param0(o), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform convolution then, global-max pooling and concatinate the output and feed it to sequential dense layer \n",
    "mutable struct DisModel\n",
    "    charset::Charset\n",
    "    embed::Embed\n",
    "    filters\n",
    "    dense_layers\n",
    "end\n",
    "\n",
    "function DisModel(charset, embeddingsize, filters, denselayers)\n",
    "    Em = Embed(length(charset.i2c), embeddingsize)\n",
    "    Em.w[:, charset.eow] = KnetArray(zeros(embeddingsize))\n",
    "    DisModel(charset, Em, filters, denselayers)\n",
    "end\n",
    "\n",
    "function (c::DisModel)(x)\n",
    "    em = c.embed(x)\n",
    "    filters_out = []\n",
    "    for f in c.filters\n",
    "        push!(filters_out, f(em))\n",
    "    end\n",
    "    out = cat(filters_out...;dims=3)\n",
    "    for l in c.dense_layers\n",
    "        out = l(out)\n",
    "    end\n",
    "    out\n",
    "end\n",
    "\n",
    "(c::DisModel)(x,y; average=true) = nll(c(x), y; average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-word loss (in this case per-batch loss)\n",
    "function loss(model, data; average=true)\n",
    "    l = 0\n",
    "    n = 0\n",
    "    a = 0\n",
    "    for (x, y) in data\n",
    "        v = model(x, y; average=false)\n",
    "        l += v[1]\n",
    "        n += v[2]\n",
    "        a += (v[1] / v[2])\n",
    "    end\n",
    "    average && return a\n",
    "    return l, n\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model(x) = K32(2,32)[0.5033598⋯]\n",
      "model(x, y; average=false) = (22.174776f0, 32)\n",
      "loss(model, ddev) = 1067.0752f0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1067.0752f0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knet.seed!(1)\n",
    "\n",
    "model = DisModel(tr_charset, 128, (\n",
    "        Conv(2,128,1,20; pdrop=0.2),\n",
    "        Conv(3,128,1,20; pdrop=0.2),\n",
    "        Conv(4,128,1,20; pdrop=0.2),\n",
    "        Conv(5,128,1,20; pdrop=0.2)\n",
    "        ),(\n",
    "        Dense(80,64,pdrop=0.3),\n",
    "        Dense(64,2,sigm,pdrop=0.3)\n",
    "        ))\n",
    "\n",
    "(x, y) = first(dtrn)\n",
    "@show model(x)\n",
    "@show model(x,y; average=false)\n",
    "@show loss(model, ddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train! (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train!(model, trn, dev, tst...)\n",
    "    bestmodel, bestloss = deepcopy(model), loss(model, dev)\n",
    "    progress!(adam(model, trn), seconds=30) do y\n",
    "        devloss = loss(model, dev)\n",
    "        tstloss = map(d->loss(model,d), tst)\n",
    "        if devloss < bestloss\n",
    "            bestloss, bestmodel = devloss, deepcopy(model)\n",
    "        end\n",
    "        println(stderr)\n",
    "        (dev=devloss, tst=tstloss, mem=Float32(CuArrays.usage[]))\n",
    "    end\n",
    "    return bestmodel\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training\n",
      "└ @ Main In[9]:1\n",
      "\n",
      "┣                    ┫ [0.01%, 1/15390, 00:21/88:45:00, 20.76s/i] (dev = 4319.8643f0, tst = (13.874476f0,), mem = 5.5916896f8)\n",
      "┣█▊                  ┫ [8.92%, 1373/15390, 00:57/10:41, 37.65i/s] (dev = 3061.2498f0, tst = (9.484567f0,), mem = 6.4781696f8)\n",
      "┣███▋                ┫ [18.51%, 2849/15390, 01:34/08:25, 40.64i/s] (dev = 2985.9307f0, tst = (9.193988f0,), mem = 6.603744f8)\n",
      "┣█████▋              ┫ [28.34%, 4362/15390, 02:10/07:39, 41.24i/s] (dev = 2912.668f0, tst = (9.072102f0,), mem = 6.72016f8)\n",
      "┣███████▌            ┫ [38.09%, 5862/15390, 02:47/07:18, 41.03i/s] (dev = 2882.1309f0, tst = (9.097249f0,), mem = 6.720154f8)\n",
      "┣█████████▌          ┫ [47.82%, 7359/15390, 03:23/07:06, 40.76i/s] (dev = 2875.1133f0, tst = (8.930739f0,), mem = 6.722447f8)\n",
      "┣███████████▌        ┫ [57.57%, 8860/15390, 04:00/06:57, 41.10i/s] (dev = 2845.9585f0, tst = (8.931266f0,), mem = 6.722447f8)\n",
      "┣█████████████▍      ┫ [67.28%, 10355/15390, 04:37/06:51, 40.71i/s] (dev = 2830.5684f0, tst = (8.881645f0,), mem = 6.703234f8)\n",
      "┣███████████████▍    ┫ [77.04%, 11857/15390, 05:13/06:47, 41.09i/s] (dev = 2843.383f0, tst = (8.947201f0,), mem = 6.6763437f8)\n",
      "┣█████████████████▎  ┫ [86.76%, 13352/15390, 05:50/06:43, 40.68i/s] (dev = 2817.8127f0, tst = (8.782613f0,), mem = 6.669359f8)\n",
      "┣███████████████████▎┫ [96.50%, 14851/15390, 06:27/06:41, 41.01i/s] (dev = 2804.5315f0, tst = (8.828023f0,), mem = 6.6628064f8)\n",
      "┣████████████████████┫ [100.00%, 15390/15390, 06:44/06:44, 38.10i/s] (dev = 2790.0962f0, tst = (8.87705f0,), mem = 6.656579f8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DisModel(Charset(Dict{Any,Int64}('ç' => 51,'Ğ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ğ' => 55…), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  …  'Ü', 'ç', 'ö', 'ü', 'Ğ', 'ğ', 'İ', 'ı', 'Ş', 'ş'], 1), Embed(P(KnetArray{Float32,2}(128,59))), (Conv(P(KnetArray{Float32,4}(2,128,1,20)), P(KnetArray{Float32,4}(1,1,20,1)), NNlib.relu, 0.2), Conv(P(KnetArray{Float32,4}(3,128,1,20)), P(KnetArray{Float32,4}(1,1,20,1)), NNlib.relu, 0.2), Conv(P(KnetArray{Float32,4}(4,128,1,20)), P(KnetArray{Float32,4}(1,1,20,1)), NNlib.relu, 0.2), Conv(P(KnetArray{Float32,4}(5,128,1,20)), P(KnetArray{Float32,4}(1,1,20,1)), NNlib.relu, 0.2)), (Dense(P(KnetArray{Float32,2}(64,80)), P(KnetArray{Float32,1}(64)), NNlib.relu, 0.3), Dense(P(KnetArray{Float32,2}(2,64)), P(KnetArray{Float32,1}(2)), Knet.sigm, 0.3)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Training\"\n",
    "epochs = 10\n",
    "ctrn = collect(ddev)\n",
    "trnx10 = collect(flatten(shuffle!(ctrn) for i in 1:epochs))\n",
    "trnmini = ctrn[1:20]\n",
    "dev = collect(dtrn)\n",
    "\n",
    "model = train!(model, trnx10, dev, trnmini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Discriminator model's accuracy:0.8583750094242416\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "real = []\n",
    "for (x, y) in dev\n",
    "    push!(results, map( x-> x[1], argmax(model(x); dims=1))...)\n",
    "    push!(real, y...)\n",
    "end\n",
    "\n",
    "Acc = sum(map( x -> x[1] == x[2], zip(real, results))) / length(real)\n",
    "println(\"CNN Discriminator model's accuracy: \", Acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
