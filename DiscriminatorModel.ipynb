{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turkish Words Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet, Test, Base.Iterators, Printf, LinearAlgebra, CuArrays, Random, IterTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arraybatch (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Charset\n",
    "    c2i::Dict{Any,Int}\n",
    "    i2c::Vector{Any}\n",
    "    eow::Int\n",
    "end\n",
    "\n",
    "function Charset(charset::String; eow=\"\")\n",
    "    i2c = [ eow; [ c for c in charset ]  ]\n",
    "    c2i = Dict( c => i for (i, c) in enumerate(i2c))\n",
    "    return Charset(c2i, i2c, c2i[eow])\n",
    "end\n",
    "\n",
    "struct TextReader\n",
    "    file::String\n",
    "    charset::Charset\n",
    "end\n",
    "\n",
    "function Base.iterate(r::TextReader, s=nothing)\n",
    "    s === nothing && (s = open(r.file))\n",
    "    eof(s) && return close(s)\n",
    "    word, label = split(readline(s))\n",
    "    return (([ get(r.charset.c2i, c, r.charset.eow) for c in word ], parse(Int, label) + 1), s)\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{TextReader}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{TextReader}) = Base.HasEltype()\n",
    "Base.eltype(::Type{TextReader}) = Vector{Int}\n",
    "\n",
    "struct WordsData\n",
    "    src::TextReader        \n",
    "    batchsize::Int         \n",
    "    maxlength::Int         \n",
    "    batchmajor::Bool       \n",
    "    bucketwidth::Int    \n",
    "    buckets::Vector        \n",
    "    batchmaker::Function   \n",
    "end\n",
    "\n",
    "function WordsData(src::TextReader; batchmaker = arraybatch, batchsize = 128, maxlength = typemax(Int),\n",
    "                batchmajor = false, bucketwidth = 2, numbuckets = min(128, maxlength ÷ bucketwidth))\n",
    "    buckets = [ [] for i in 1:numbuckets ] # buckets[i] is an array of sentence pairs with similar length\n",
    "    WordsData(src, batchsize, maxlength, batchmajor, bucketwidth, buckets, batchmaker)\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{WordsData}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{WordsData}) = Base.HasEltype()\n",
    "Base.eltype(::Type{WordsData}) = Tuple{Array{Int64,2},Array{Int64,1}}\n",
    "\n",
    "function Base.iterate(d::WordsData, state=nothing)\n",
    "    if state == 0 # When file is finished but buckets are partially full \n",
    "        for i in 1:length(d.buckets)\n",
    "            if length(d.buckets[i]) > 0\n",
    "                batch = d.batchmaker(d, d.buckets[i])\n",
    "                d.buckets[i] = []\n",
    "                return batch, state\n",
    "            end\n",
    "        end\n",
    "        return nothing # Finish iteration\n",
    "    elseif state === nothing\n",
    "        # Just to make sure\n",
    "        for i in 1:length(d.buckets)\n",
    "            d.buckets[i] = []\n",
    "        end\n",
    "        state = nothing\n",
    "    end\n",
    "\n",
    "    while true\n",
    "        src_next = iterate(d.src, state)\n",
    "        \n",
    "        if src_next === nothing\n",
    "            state = 0\n",
    "            return iterate(d, state)\n",
    "        end\n",
    "        \n",
    "        (src_word, src_state) = src_next\n",
    "        state = src_state\n",
    "        src_length = length(src_word[1])\n",
    "        \n",
    "        (src_length > d.maxlength) && continue\n",
    "\n",
    "        i = Int(ceil(src_length / d.bucketwidth))\n",
    "        i > length(d.buckets) && (i = length(d.buckets))\n",
    "\n",
    "        push!(d.buckets[i], src_word)\n",
    "        if length(d.buckets[i]) == d.batchsize\n",
    "            batch = d.batchmaker(d, d.buckets[i])\n",
    "            d.buckets[i] = []\n",
    "            return batch, state\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function arraybatch(d::WordsData, bucket)\n",
    "    src_eow = d.src.charset.eow\n",
    "    \n",
    "    x = zeros(Int64, length(bucket), d.maxlength) # default d.batchmajor is false\n",
    "    for (i, v) in enumerate(bucket)\n",
    "        to_be_added = fill(src_eow, d.maxlength - length(v[1]))\n",
    "        x[i,:] = [v[1]; to_be_added]\n",
    "    end\n",
    "    \n",
    "    y = [ x[2] for x in bucket]\n",
    "    \n",
    "    d.batchmajor && (x = x')\n",
    "    return (x, y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Reading data\n",
      "└ @ Main In[3]:5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WordsData(TextReader(\"discriminator_labeled_set/dis.dev\", Charset(Dict{Any,Int64}('ç' => 51,'Ğ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ğ' => 55…), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  …  'Ü', 'ç', 'ö', 'ü', 'Ğ', 'ğ', 'İ', 'ı', 'Ş', 'ş'], 1)), 32, 25, false, 1, Array{Any,1}[[], [], [], [], [], [], [], [], [], []  …  [], [], [], [], [], [], [], [], [], []], arraybatch)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_set = \"ABCDEFGHIJKLMNOPRSTUVYZabcdefghijklmnoprstuvyzÇÖÜçöüĞğİıŞş\"\n",
    "datadir = \"discriminator_labeled_set\"\n",
    "\n",
    "BATCHSIZE, MAXLENGTH = 32, 25\n",
    "@info \"Reading data\"\n",
    "tr_charset = Charset(char_set)\n",
    "tr_train = TextReader(\"$datadir/dis.train\", tr_charset)\n",
    "tr_dev = TextReader(\"$datadir/dis.dev\", tr_charset)\n",
    "dtrn = WordsData(tr_train, batchsize=BATCHSIZE, maxlength=MAXLENGTH, bucketwidth = 1)\n",
    "ddev = WordsData(tr_dev, batchsize=BATCHSIZE, maxlength=MAXLENGTH, bucketwidth = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Embed; w; end\n",
    "Embed(charsetsize::Int, embedsize::Int) = Embed(param(embedsize, charsetsize))\n",
    "(l::Embed)(x) = (em=permutedims(l.w[:, x], [3, 1, 2]); ds=size(em); em=reshape(em, ds[1], ds[2], 1, ds[3])) # (E, B, T) -> (T, E, 1, B)\n",
    "\n",
    "struct Conv; w; b; f; p; end\n",
    "(c::Conv)(x) = (co=conv4(c.w, dropout(x,c.p)); c.f.(pool((co .+ c.b); window=(size(co, 1), size(co, 2)))))\n",
    "Conv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)\n",
    "\n",
    "struct Dense; w; b; f; p; end\n",
    "(d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul\n",
    "Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i), param0(o), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform convolution then, global-max pooling and concatinate the output and feed it to sequential dense layer \n",
    "mutable struct DisModel\n",
    "    charset::Charset\n",
    "    embed::Embed\n",
    "    filters\n",
    "    dense_layers\n",
    "end\n",
    "\n",
    "function DisModel(charset, embeddingsize, filters, denselayers)\n",
    "    Em = Embed(length(charset.i2c), embeddingsize)\n",
    "    Em.w[:, charset.eow] = KnetArray(zeros(embeddingsize))\n",
    "    DisModel(charset, Em, filters, denselayers)\n",
    "end\n",
    "\n",
    "function (c::DisModel)(x)\n",
    "    em = c.embed(x)\n",
    "    filters_out = []\n",
    "    for f in c.filters\n",
    "        push!(filters_out, f(em))\n",
    "    end\n",
    "    out = cat(filters_out...;dims=3)\n",
    "    for l in c.dense_layers\n",
    "        out = l(out)\n",
    "    end\n",
    "    out\n",
    "end\n",
    "\n",
    "(c::DisModel)(x,y; average=true) = nll(c(x), y; average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-word loss (in this case per-batch loss)\n",
    "function loss(model, data; average=true)\n",
    "    l = 0\n",
    "    n = 0\n",
    "    a = 0\n",
    "    for (x, y) in data\n",
    "        v = model(x, y; average=false)\n",
    "        l += v[1]\n",
    "        n += v[2]\n",
    "        a += (v[1] / v[2])\n",
    "    end\n",
    "    average && return a\n",
    "    return l, n\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model(x) = K32(2,32)[0.5033598⋯]\n",
      "model(x, y; average=false) = (22.174776f0, 32)\n",
      "loss(model, ddev) = 1067.0752f0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1067.0752f0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knet.seed!(1)\n",
    "\n",
    "model = DisModel(tr_charset, 128, (\n",
    "        Conv(2,128,1,20; pdrop=0.2),\n",
    "        Conv(3,128,1,20; pdrop=0.2),\n",
    "        Conv(4,128,1,20; pdrop=0.2),\n",
    "        Conv(5,128,1,20; pdrop=0.2)\n",
    "        ),(\n",
    "        Dense(80,64,pdrop=0.3),\n",
    "        Dense(64,2,sigm,pdrop=0.3)\n",
    "        ))\n",
    "\n",
    "(x, y) = first(dtrn)\n",
    "@show model(x)\n",
    "@show model(x,y; average=false)\n",
    "@show loss(model, ddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train! (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train!(model, trn, dev, tst...)\n",
    "    bestmodel, bestloss = deepcopy(model), loss(model, dev)\n",
    "    progress!(adam(model, trn), seconds=30) do y\n",
    "        devloss = loss(model, dev)\n",
    "        tstloss = map(d->loss(model,d), tst)\n",
    "        if devloss < bestloss\n",
    "            bestloss, bestmodel = devloss, deepcopy(model)\n",
    "        end\n",
    "        println(stderr)\n",
    "        (dev=devloss, tst=tstloss, mem=Float32(CuArrays.usage[]))\n",
    "    end\n",
    "    return bestmodel\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training\n",
      "└ @ Main In[9]:1\n",
      "\n",
      "┣                    ┫ [0.00%, 1/62290, 00:13/230:14:47, 13.31s/i] (dev = 1066.947f0, tst = (13.856159f0,), mem = 5.474823f8)\n",
      "┣█▋                  ┫ [8.50%, 5294/62290, 00:45/08:47, 167.94i/s] (dev = 717.3556f0, tst = (9.145436f0,), mem = 6.468418f8)\n",
      "┣███▎                ┫ [16.29%, 10149/62290, 01:16/07:49, 153.29i/s] (dev = 699.28925f0, tst = (9.1476145f0,), mem = 6.5820256f8)\n",
      "┣████▉               ┫ [24.41%, 15207/62290, 01:48/07:22, 160.73i/s] (dev = 684.7165f0, tst = (8.709965f0,), mem = 6.5869946f8)\n",
      "┣██████▋             ┫ [33.23%, 20701/62290, 02:19/06:58, 176.66i/s] (dev = 679.76514f0, tst = (9.008552f0,), mem = 6.5869946f8)\n",
      "┣████████▏           ┫ [41.03%, 25557/62290, 02:51/06:56, 153.83i/s] (dev = 675.2181f0, tst = (8.800694f0,), mem = 6.5869946f8)\n",
      "┣█████████▊          ┫ [49.07%, 30566/62290, 03:22/06:52, 157.92i/s] (dev = 666.7464f0, tst = (8.607854f0,), mem = 6.5980256f8)\n",
      "┣███████████▍        ┫ [57.15%, 35597/62290, 03:54/06:49, 160.66i/s] (dev = 669.7829f0, tst = (8.895861f0,), mem = 6.584183f8)\n",
      "┣█████████████       ┫ [65.51%, 40804/62290, 04:25/06:45, 166.06i/s] (dev = 665.57336f0, tst = (8.911293f0,), mem = 6.6099955f8)\n",
      "┣██████████████▋     ┫ [73.61%, 45849/62290, 04:56/06:43, 161.12i/s] (dev = 660.33136f0, tst = (8.470383f0,), mem = 6.60709f8)\n",
      "┣████████████████▎   ┫ [81.80%, 50952/62290, 05:28/06:41, 161.07i/s] (dev = 660.95105f0, tst = (8.482557f0,), mem = 6.604128f8)\n",
      "┣█████████████████▉  ┫ [89.97%, 56041/62290, 05:59/06:40, 161.95i/s] (dev = 659.95135f0, tst = (8.49606f0,), mem = 6.5909984f8)\n",
      "┣███████████████████▌┫ [98.02%, 61054/62290, 06:31/06:39, 159.58i/s] (dev = 671.69885f0, tst = (8.846307f0,), mem = 6.56079f8)\n",
      "┣████████████████████┫ [100.00%, 62290/62290, 06:40/06:40, 155.91i/s] (dev = 658.23114f0, tst = (8.5498085f0,), mem = 6.5240915f8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DisModel(Charset(Dict{Any,Int64}('ç' => 51,'Ğ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ğ' => 55…), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  …  'Ü', 'ç', 'ö', 'ü', 'Ğ', 'ğ', 'İ', 'ı', 'Ş', 'ş'], 1), Embed(P(KnetArray{Float32,2}(128,59))), (Conv(P(KnetArray{Float32,4}(2,128,1,20)), P(KnetArray{Float32,4}(1,1,20,1)), NNlib.relu, 0.2), Conv(P(KnetArray{Float32,4}(3,128,1,20)), P(KnetArray{Float32,4}(1,1,20,1)), NNlib.relu, 0.2), Conv(P(KnetArray{Float32,4}(4,128,1,20)), P(KnetArray{Float32,4}(1,1,20,1)), NNlib.relu, 0.2), Conv(P(KnetArray{Float32,4}(5,128,1,20)), P(KnetArray{Float32,4}(1,1,20,1)), NNlib.relu, 0.2)), (Dense(P(KnetArray{Float32,2}(64,80)), P(KnetArray{Float32,1}(64)), NNlib.relu, 0.3), Dense(P(KnetArray{Float32,2}(2,64)), P(KnetArray{Float32,1}(2)), Knet.sigm, 0.3)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Training\"\n",
    "epochs = 10\n",
    "ctrn = collect(dtrn)\n",
    "trnx10 = collect(flatten(shuffle!(ctrn) for i in 1:epochs))\n",
    "trnmini = ctrn[1:20]\n",
    "dev = collect(ddev)\n",
    "\n",
    "model = train!(model, trnx10, dev, trnmini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Discriminator model's accuracy: 0.878341561341336\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "real = []\n",
    "for (x, y) in dev\n",
    "    push!(results, map( x-> x[1], argmax(model(x); dims=1))...)\n",
    "    push!(real, y...)\n",
    "end\n",
    "\n",
    "Acc = sum(map( x -> x[1] == x[2], zip(real, results))) / length(real)\n",
    "println(\"CNN Discriminator model's accuracy: \", Acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: CNN Discriminator model performance report\n",
      "└ @ Main In[11]:9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.88\n",
      "Recall 0.50\n",
      "Precision 0.87\n",
      "F1-Score 0.63\n"
     ]
    }
   ],
   "source": [
    "Acc = sum(map( x -> x[1] == x[2], zip(real, results))) / length(real)\n",
    "TN = sum(map(x -> x[1] == x[2] == 1, zip(real, results)))\n",
    "TP = sum(map(x -> x[1] == x[2] == 2, zip(real, results)))\n",
    "FP = sum(map(x -> x[1] != x[2] == 2, zip(real, results)))\n",
    "P = TP / (TP + FP)\n",
    "R = TP / (TP + TN)\n",
    "F1 = 2 * P * R / ( P + R )\n",
    "\n",
    "@info \"CNN Discriminator model performance report\"\n",
    "println(@sprintf(\"Accuracy %.2f\", Acc))\n",
    "println(@sprintf(\"Recall %.2f\", R))\n",
    "println(@sprintf(\"Precision %.2f\", P))\n",
    "println(@sprintf(\"F1-Score %.2f\", F1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
