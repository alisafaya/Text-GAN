{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turkish Words Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet, Test, Base.Iterators, Printf, LinearAlgebra, CuArrays, Random, IterTools, StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arraybatch (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Charset\n",
    "    c2i::Dict{Any,Int}\n",
    "    i2c::Vector{Any}\n",
    "    eow::Int\n",
    "end\n",
    "\n",
    "function Charset(charset::String; eow=\"\")\n",
    "    i2c = [ eow; [ c for c in charset ]  ]\n",
    "    c2i = Dict( c => i for (i, c) in enumerate(i2c))\n",
    "    return Charset(c2i, i2c, c2i[eow])\n",
    "end\n",
    "\n",
    "struct TextReader\n",
    "    file::String\n",
    "    charset::Charset\n",
    "end\n",
    "\n",
    "function Base.iterate(r::TextReader, s=nothing)\n",
    "    s === nothing && (s = open(r.file))\n",
    "    eof(s) && return close(s)\n",
    "    word, label = split(readline(s))\n",
    "    return (([ get(r.charset.c2i, c, r.charset.eow) for c in word ], parse(Int, label) + 1), s)\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{TextReader}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{TextReader}) = Base.HasEltype()\n",
    "Base.eltype(::Type{TextReader}) = Vector{Int}\n",
    "\n",
    "struct WordsData\n",
    "    src::TextReader        \n",
    "    batchsize::Int         \n",
    "    maxlength::Int         \n",
    "    batchmajor::Bool       \n",
    "    bucketwidth::Int    \n",
    "    buckets::Vector        \n",
    "    batchmaker::Function   \n",
    "end\n",
    "\n",
    "function WordsData(src::TextReader; batchmaker = arraybatch, batchsize = 128, maxlength = typemax(Int),\n",
    "                batchmajor = false, bucketwidth = 2, numbuckets = min(128, maxlength ÷ bucketwidth))\n",
    "    buckets = [ [] for i in 1:numbuckets ] # buckets[i] is an array of sentence pairs with similar length\n",
    "    WordsData(src, batchsize, maxlength, batchmajor, bucketwidth, buckets, batchmaker)\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{WordsData}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{WordsData}) = Base.HasEltype()\n",
    "Base.eltype(::Type{WordsData}) = Tuple{Array{Int64,2},Array{Int64,1}}\n",
    "\n",
    "function Base.iterate(d::WordsData, state=nothing)\n",
    "    if state == 0 # When file is finished but buckets are partially full \n",
    "        for i in 1:length(d.buckets)\n",
    "            if length(d.buckets[i]) > 0\n",
    "                batch = d.batchmaker(d, d.buckets[i])\n",
    "                d.buckets[i] = []\n",
    "                return batch, state\n",
    "            end\n",
    "        end\n",
    "        return nothing # Finish iteration\n",
    "    elseif state === nothing\n",
    "        # Just to make sure\n",
    "        for i in 1:length(d.buckets)\n",
    "            d.buckets[i] = []\n",
    "        end\n",
    "        state = nothing\n",
    "    end\n",
    "\n",
    "    while true\n",
    "        src_next = iterate(d.src, state)\n",
    "        \n",
    "        if src_next === nothing\n",
    "            state = 0\n",
    "            return iterate(d, state)\n",
    "        end\n",
    "        \n",
    "        (src_word, src_state) = src_next\n",
    "        state = src_state\n",
    "        src_length = length(src_word[1])\n",
    "        \n",
    "        (src_length > d.maxlength) && continue\n",
    "\n",
    "        i = Int(ceil(src_length / d.bucketwidth))\n",
    "        i > length(d.buckets) && (i = length(d.buckets))\n",
    "\n",
    "        push!(d.buckets[i], src_word)\n",
    "        if length(d.buckets[i]) == d.batchsize\n",
    "            batch = d.batchmaker(d, d.buckets[i])\n",
    "            d.buckets[i] = []\n",
    "            return batch, state\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function arraybatch(d::WordsData, bucket)\n",
    "    src_eow = d.src.charset.eow\n",
    "    \n",
    "    x = zeros(Int64, length(bucket), d.maxlength) # default d.batchmajor is false\n",
    "    for (i, v) in enumerate(bucket)\n",
    "        to_be_added = fill(src_eow, d.maxlength - length(v[1]))\n",
    "        x[i,:] = [v[1]; to_be_added]\n",
    "    end\n",
    "    \n",
    "    y = [ x[2] for x in bucket]\n",
    "    \n",
    "    d.batchmajor && (x = x')\n",
    "    return (x, y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Reading data\n",
      "└ @ Main In[3]:5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WordsData(TextReader(\"discriminator_labeled_set/dis.dev\", Charset(Dict{Any,Int64}('ç' => 51,'Ğ' => 54,'E' => 6,'Z' => 24,'o' => 39,'B' => 3,'h' => 32,'i' => 33,'r' => 41,'ğ' => 55…), Any[\"\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'  …  'Ü', 'ç', 'ö', 'ü', 'Ğ', 'ğ', 'İ', 'ı', 'Ş', 'ş'], 1)), 32, 25, false, 1, Array{Any,1}[[], [], [], [], [], [], [], [], [], []  …  [], [], [], [], [], [], [], [], [], []], arraybatch)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_set = \"ABCDEFGHIJKLMNOPRSTUVYZabcdefghijklmnoprstuvyzÇÖÜçöüĞğİıŞş\"\n",
    "datadir = \"discriminator_labeled_set\"\n",
    "\n",
    "BATCHSIZE, MAXLENGTH = 32, 25\n",
    "@info \"Reading data\"\n",
    "tr_charset = Charset(char_set)\n",
    "tr_train = TextReader(\"$datadir/dis.train\", tr_charset)\n",
    "tr_dev = TextReader(\"$datadir/dis.dev\", tr_charset)\n",
    "dtrn = WordsData(tr_train, batchsize=BATCHSIZE, maxlength=MAXLENGTH, bucketwidth = 1)\n",
    "ddev = WordsData(tr_dev, batchsize=BATCHSIZE, maxlength=MAXLENGTH, bucketwidth = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Embed; w; end\n",
    "Embed(charsetsize::Int, embedsize::Int) = Embed(param(embedsize, charsetsize))\n",
    "(l::Embed)(x) = (em=permutedims(l.w[:, x], [3, 1, 2]); ds=size(em); em=reshape(em, ds[1], ds[2], 1, ds[3])) # (E, B, T) -> (T, E, 1, B)\n",
    "\n",
    "struct Conv; w; b; f; p; end\n",
    "(c::Conv)(x) = (co=conv4(c.w, dropout(x,c.p)); c.f.(pool((co .+ c.b); window=(size(x, 1), size(x, 2)))))\n",
    "Conv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)\n",
    "\n",
    "struct Dense; w; b; f; p; end\n",
    "(d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul\n",
    "Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i), param0(o), f, pdrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform convolution then, global-max pooling and concatinate the output and feed it to sequential dense layer \n",
    "mutable struct DisModel\n",
    "    charset::Charset\n",
    "    embed::Embed\n",
    "    filters\n",
    "    dense_layers\n",
    "end\n",
    "\n",
    "function DisModel(charset, embeddingsize, filters, denselayers)\n",
    "    Em = Embed(length(charset.i2c), embeddingsize)\n",
    "    Em.w[:, charset.eow] = KnetArray(zeros(embeddingsize))\n",
    "    DisModel(charset, Em, filters, denselayers)\n",
    "end\n",
    "\n",
    "function (c::DisModel)(x)\n",
    "    em = c.embed(x)\n",
    "    filters_out = []\n",
    "    for f in c.filters\n",
    "        push!(filters_out, f(em))\n",
    "    end\n",
    "    out = cat(filters_out...;dims=3)\n",
    "    for l in c.dense_layers\n",
    "        out = l(out)\n",
    "    end\n",
    "    out\n",
    "end\n",
    "\n",
    "(c::DisModel)(x,y; average=true) = nll(c(x), y; average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-word loss (in this case per-batch loss)\n",
    "function loss(model, data; average=true)\n",
    "    l = 0\n",
    "    n = 0\n",
    "    a = 0\n",
    "    for (x, y) in data\n",
    "        v = model(x, y; average=false)\n",
    "        l += v[1]\n",
    "        n += v[2]\n",
    "        a += (v[1] / v[2])\n",
    "    end\n",
    "    average && return a\n",
    "    return l, n\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model(x) = K32(2,32)[0.5025334⋯]\n",
      "model(x, y; average=false) = (22.184029f0, 32)\n",
      "loss(model, ddev) = 1066.8767f0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1066.8767f0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knet.seed!(1)\n",
    "\n",
    "model = DisModel(tr_charset, 128, (\n",
    "        Conv(2,128,1,20; pdrop=0.2),\n",
    "        Conv(3,128,1,20; pdrop=0.2),\n",
    "        Conv(4,128,1,20; pdrop=0.2),\n",
    "#         Conv(5,1,1,5; pdrop=0.2)\n",
    "        ),(\n",
    "        Dense(60,64,pdrop=0.3),\n",
    "        Dense(64,2,sigm,pdrop=0.3)\n",
    "        ))\n",
    "\n",
    "(x, y) = first(dtrn)\n",
    "@show model(x)\n",
    "@show model(x,y; average=false)\n",
    "@show loss(model, ddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train! (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train!(model, trn, dev, tst...)\n",
    "    bestmodel, bestloss = deepcopy(model), loss(model, dev)\n",
    "    progress!(adam(model, trn), seconds=30) do y\n",
    "        devloss = loss(model, dev)\n",
    "        tstloss = map(d->loss(model,d), tst)\n",
    "        if devloss < bestloss\n",
    "            bestloss, bestmodel = devloss, deepcopy(model)\n",
    "        end\n",
    "        println(stderr)\n",
    "        (dev=devloss, tst=tstloss, mem=Float32(CuArrays.usage[]))\n",
    "    end\n",
    "    return bestmodel\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training\n",
      "└ @ Main In[13]:1\n",
      "\n",
      "┣                    ┫ [0.00%, 1/62290, 00:15/267:44:58, 15.47s/i] (dev = 1066.7972f0, tst = (13.863449f0,), mem = 6.084304f8)\n",
      "┣▌                   ┫ [2.97%, 1850/62290, 00:47/26:17, 58.95i/s] (dev = 757.9115f0, tst = (10.026481f0,), mem = 6.73748f8)\n",
      "┣█▏                  ┫ [5.86%, 3651/62290, 01:18/22:15, 57.39i/s] (dev = 734.9005f0, tst = (9.882441f0,), mem = 6.742934f8)\n",
      "┣█▊                  ┫ [8.87%, 5525/62290, 01:50/20:36, 59.71i/s] (dev = 723.7071f0, tst = (9.744415f0,), mem = 6.7429235f8)\n",
      "┣██▍                 ┫ [11.93%, 7429/62290, 02:21/19:42, 60.68i/s] (dev = 712.6051f0, tst = (9.568416f0,), mem = 6.808178f8)\n",
      "┣███                 ┫ [15.00%, 9345/62290, 02:52/19:09, 61.08i/s] (dev = 706.6422f0, tst = (9.471064f0,), mem = 6.8789094f8)\n",
      "┣███▌                ┫ [18.06%, 11251/62290, 03:24/18:48, 60.75i/s] (dev = 703.01807f0, tst = (9.365469f0,), mem = 6.8825466f8)"
     ]
    }
   ],
   "source": [
    "@info \"Training\"\n",
    "epochs = 10\n",
    "ctrn = collect(dtrn)\n",
    "trnx10 = collect(flatten(shuffle!(ctrn) for i in 1:epochs))\n",
    "trnmini = ctrn[1:20]\n",
    "dev = collect(ddev)\n",
    "\n",
    "model = train!(model, trnx10, dev, trnmini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "real = []\n",
    "for (x, y) in dev\n",
    "    push!(results, map( x-> x[1], argmax(model(x); dims=1))...)\n",
    "    push!(real, y...)\n",
    "end\n",
    "\n",
    "Acc = sum(map( x -> x[1] == x[2], zip(real, results))) / length(real)\n",
    "println(\"CNN Discriminator model's accuracy:\", Acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
